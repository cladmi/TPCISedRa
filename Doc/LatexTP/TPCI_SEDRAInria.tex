%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Programming/Coding Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when
% writing assignment content.
%
% This template uses a Perl script as an example snippet of code, most other
% languages are also usable. Configure them in the "CODE INCLUSION
% CONFIGURATION" section.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{hyperref} % For urls
\usepackage{dirtree}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
%\lhead{\hmwkAuthorName} % Top left header
%\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle} % Top center head
\lhead{\hmwkTitle} % Top center head
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	CODE INCLUSION CONFIGURATION
%----------------------------------------------------------------------------------------

\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0} % This is the color used for comments
\lstloadlanguages{Perl, Java, Python, C++} % Load Perl syntax for listings, for a list of other languages supported see: ftp://ftp.tex.ac.uk/tex-archive/macros/latex/contrib/listings/listings.pdf

\lstset{language=C++, % Use C++
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % functions bold and blue
        keywordstyle=[2]\color{Purple}, % function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=4, % 5 spaces per tab
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=2 % Line numbers go in steps of 5
}
\lstset{language=Java, % Use Java in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % functions bold and blue
        keywordstyle=[2]\color{Purple}, %  function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=4, % 5 spaces per tab
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=2 % Line numbers go in steps of 5
}
\lstset{language=Python, % Use Python in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % functions bold and blue
        keywordstyle=[2]\color{Purple}, % function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=4, % 5 spaces per tab
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=2 % Line numbers go in steps of 2
}

\lstset{language=Perl, % Use Perl in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % Perl functions bold and blue
        keywordstyle=[2]\color{Purple}, % Perl function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=5, % 5 spaces per tab
        %
        % Put standard Perl functions not included in the default language here
        morekeywords={rand},
        %
        % Put Perl function parameters here
        morekeywords=[2]{on, off, interp},
        %
        % Put user defined functions here
        morekeywords=[3]{test},
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=5 % Line numbers go in steps of 5
}

% Creates a new command to include a perl script, the first parameter is the filename of the script (without .pl), the second parameter is the caption
\newcommand{\perlscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.pl}
\end{itemize}
}

\newcommand{\javascript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.java}
\end{itemize}
}

\newcommand{\pythonscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.py}
\end{itemize}
}

\newcommand{\cppscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.cpp}
\end{itemize}
}

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Java/C++/Python Exercices} % Assignment title
\newcommand{\hmwkDueDate}{Tuesday,\ November\ 17,\ 2015} % Due date
\newcommand{\hmwkClass}{Continuous Integration Seminar} % Course/class
\newcommand{\hmwkClassTime}{13h30} % Class/lecture time
\newcommand{\hmwkClassInstructor}{\url{sed.inrialpes.fr}} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Maurice Bremond, Gaetan Harter, David Parsons -- SED INRIA Rh√¥ne-Alpes} % Your name


%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
%\vspace{2in}
\textsc{\hmwkClass}\\
\textbf{\hmwkTitle}\\
%\normalsize\vspace{0.1in}\small{\hmwkDueDate}\\
\vspace{0.1in}\large{\textit{\hmwkClassInstructor}}%\ \hmwkClassTime}}
%\vspace{3in}
}

\author{\textsf{\hmwkAuthorName}}
\date{\textit{\hmwkDueDate}} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

%\newpage
\tableofcontents
%\newpage


%----------------------------------------------------------------------------------------
%	JAVA
%----------------------------------------------------------------------------------------

% To have just one problem per page, simply put a \clearpage after each problem
\begin{homeworkProblem}[Java Exercise]

\section{Preamble}

To go through this exercise, you will need to install
\begin{itemize}
\item \texttt{Git} (apt-get install git | yum install git)
\item A JDK (apt-get install openjdk-7-jdk | yum install java-1.7.0-openjdk)
\item \texttt{Maven} (apt-get install maven | yum install apache-maven)
\end{itemize}

You also need an account on both \url{gforge.inria.fr} and \url{ci.inria.fr} and to be a member of the \texttt{tpcisedra} project on both platforms.

\section{Setup}

\subsection{Create a personal copy of the git repository from INRIA forge and clone it}
First, you will create your personal \texttt{git} repository on the INRIA forge as a branch of the main repository for the \texttt{tpcisedra} project~:
\begin{itemize}
\item Go to \url{https://gforge.inria.fr/projects/tpcisedra/}
\item Click on the \textbf{\texttt{CODE SOURCE}} or \textbf{\texttt{SCM}} tab
\item Click on \textbf{\texttt{Create a personal repository}}
\item Back to the \textbf{\texttt{SCM}} tab, look for the command to access your personal repository.
\end{itemize}

\textbf{WARNING~: do not use the anonymous access (containing \texttt{anonscm}) }


Then on a terminal, clone the content of your personal \texttt{git} repository. The correct command should look like this~:
\begin{lstlisting}
$ git clone git+ssh://<yourlogin>@scm.gforge.inria.fr/gitroot/tpcisedra/
    users/<yourlogin>.git
$ cd <yourlogin>/java
\end{lstlisting}

\
You should have retrieved the following file tree~:\\
{\centering\small
            \begin{minipage}[t]{0.3\linewidth}
\dirtree{%
.1 tpcisedra/java.
.2 pom.xml.
.2 src.
.3 main.
.4 java.
.5 fr.
.6 inria.
.7 sed.
.8 Sphere.java.
.3 tst.
.4 java.
.5 fr.
.6 inria.
.7 sed.
.8 SphereTest.java.
}
\end{minipage}
}


The project is made up of~:
\begin{itemize}
\item A Maven \textbf{\texttt{Project Object Model}} file named \texttt{pom.xml};
\item A file \texttt{Sphere.java} implementing the class \texttt{Sphere};
\item A file \texttt{SphereTest.java} implementing its test class \texttt{SphereTest}.
\end{itemize}

\subsection{Check that you can build the project}
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn package
\end{lstlisting}

You should see these lines (among others)~:
\begin{lstlisting}
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
\end{lstlisting}



%--------------------------------------
\section{Testing your code locally}

\subsection{Run the (single) test}
\begin{lstlisting}
$ mvn test
\end{lstlisting}

You should see something like
\begin{lstlisting}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running fr.inria.sed.SphereTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.069 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
\end{lstlisting}



%--------------------------------------
\section{Testing your code remotely on ci.inria.fr}

\subsection{Log into the project's Jenkins instance}
Connect to the INRIA Continuous Integration web portal~: \url{https://ci.inria.fr/} \\
Log in and click \textbf{\texttt{Dashboard}} in the top menu \\
You should have been added to project \textbf{\texttt{TPCISedRa}}, click on the \textbf{\texttt{Jenkins}} button \\
You may be prompted to log into \texttt{Jenkins}, use the same login/passwd as for the ci portal

\subsection{Create a new Jenkins item}
From our \texttt{Jenkins} dashboard page (\url{https://ci.inria.fr/tpcisedra/}), click \textbf{\texttt{New Item}} in the menu on the left
Provide a name for this new item (avoid spaces since it is likely to lead to errors) and select \textbf{\texttt{Maven project}}

\subsection{Git configuration}
In the new item's configuration page (which you will be redirected to after clicking \textbf{\texttt{OK}} on the \texttt{New Item} page), choose \texttt{git} as your \textbf{\texttt{Source Code Manager}} and copy the \emph{anonymous} url to your personal repository into the appropriate field~:
\begin{lstlisting}
https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<yourlogin>.git
\end{lstlisting}
\end{homeworkProblem}

\subsection{Build configuration}
In the \textbf{\texttt{Build}} section, change the root POM path to \texttt{java/pom.xml} and type \texttt{test} in \textbf{\texttt{Goals and options}} section.

\subsection{Save and run}
Click \textbf{\texttt{Save}} at the bottom of the page \\
Click \textbf{\texttt{Build Now}} in the menu on the left

\subsection{Check the output}
In the \textbf{\texttt{Build History}} on the left, click on the last build (hopefully \#1), then select \textbf{\texttt{Console Output}} \\
You can also check the \textbf{\texttt{Test Result}}



%--------------------------------------
\section{Exercice 1}

Have a look at the code of the method \texttt{Sphere::computeVolume()}.\\
To do so, edit \texttt{tpcisedra/java/src/main/java/fr/inria/sed/Sphere.java}.

The code should be like that~:
\begin{lstlisting}
public double computeVolume1() {
  return 4 * Math.PI * Math.pow(radius_, 3) / 3;
}
\end{lstlisting}


We might want the value~: \verb?4 * Math.PI / 3? to be computed once and for all.

\subsubsection{TODO~:}
\begin{itemize}
\item Extract this value into a class data member
\item Run the test again. It should fail.
\end{itemize}

Here is the output you should get~:
\begin{lstlisting}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running fr.inria.sed.SphereTest
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.076 sec <<< FAILURE!

Results :

Failed tests:   testComputeVolume(fr.inria.sed.SphereTest):
    expected:<14.137166941154069> but was:<14.137166941154067>

Tests run: 1, Failures: 1, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
\end{lstlisting}

\subsubsection{TODO~:}
\begin{itemize}
\item Check that tests fail on CI. \\
Hint~: have you commited and pushed your changes ?
\end{itemize}

\section{Exercice 2}

Why does the test in \texttt{SphereTest.java} fail ?

This is because of floating point arithmetics \emph{rounding errors}.

Our response to this issue strongly depends on what kind of application we are working on~:
\begin{itemize}
\item In some cases, we want to be aware that something has changed, even when the change is the tiniest. In that case, the test we already have is just what we want.
\item In other cases, we need not worry about such a small difference and hence do not want to be bothered by tests complaining.
\end{itemize}

\subsubsection{TODO~:}
\begin{itemize}
\item Find a way to modify the appropriate test in \texttt{SphereTest.java}
so small rounding differences do not cause errors.
\item Check that tests pass on CI.
\end{itemize}


%--------------------------------------
\section{Test Coverage}

At this stage, all our tests pass. But what does that mean regarding our application ?

Not much you may say, but can you quantify it and will you be able to tell on a real project ?

This is when \textbf{test coverage} becomes handy.

\subsection{Run test coverage}

Run the following \texttt{maven} command~:
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn cobertura:cobertura
\end{lstlisting}

Cobertura should have produced test coverage results in the following directory~:\\
\texttt{yourpath/tpcisedra/java/target/site/cobertura}


Use your favorite WEB browser (firefox, chrome, iceweasel, \...) to visualize the generated results of the test coverage
\begin{lstlisting}
$ firefox target/site/cobertura/index.html &
\end{lstlisting}

\section{Exercise 3}

\subsubsection{TODO~:}

\begin{itemize}
\item Populate your tests to achieve 100\% test coverage.\\
Hint~: you may not need any additional tests ;)
\end{itemize}


\subsection{Integrate cobertura to your reporting local website}

Add the following to the file  \texttt{pom.xml}
\begin{lstlisting}
  <reporting>
    <plugins>
      <plugin>
        <groupId>org.codehaus.mojo</groupId>
        <artifactId>cobertura-maven-plugin</artifactId>
        <version>2.7</version>
      </plugin>
    </plugins>
  </reporting>
\end{lstlisting}

The report generation is now included in the build life cycle (\textbf{\texttt{site}} phase).

\subsubsection{TODO~:}

\begin{itemize}
\item Generate the report~:
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn site
\end{lstlisting}

\item Use your favorite WEB browser (firefox, chrome, iceweasel, \...) to visualize the generated report~:
\begin{lstlisting}
iceweasel target/site/project-reports.html &
\end{lstlisting}
\end{itemize}

\section{Exercise 3bis - Coverage Report on Jenkins}

\subsection{Adding build feedback}
One of the good things with \texttt{Jenkins} is its ability to nicely present your test results. \\
The tools we used to run tests and code quality checks have been selected based on the availability of the corresponding \texttt{Jenkins} plugins.

\subsection{Add coverage report}
\begin{itemize}
\item Go back to your item's configuration page (use the menu on the left)
\item Replace your build's \textbf{\texttt{Goals and options}} with~: \\
\texttt{cobertura:cobertura -Dcobertura.report.format=xml}
\item Click on \textbf{\texttt{Add post-build action}} and select \textbf{\texttt{Publish Cobertura Coverage Report}} from the drop-down menu
\item The \textbf{\texttt{Cobertura xml report pattern}} is~:\\
\texttt{**/target/site/cobertura/coverage.xml} (it is the example provided below the field)
\item Save and Run the test
\item Check the output~: in the \texttt{Build History} on the left, click on the last build, you should have a new entry named \textbf{\texttt{Coverage Report}}, have a look at it
\end{itemize}



\section{Add a new class to our project}

Let's add a new class \texttt{Alphabet} and its test class \texttt{AlphabetTest} to our project
\begin{lstlisting}
$ git merge alpha
\end{lstlisting}


\section{Exercice 4}
\begin{itemize}
\item Generate and visualize the corresponding coverage report
\item Make what changes are necessary to achieve 100\% test coverage
\item Check that you get the same results on Jenkins
\end{itemize}

%--------------------------------------
\section{Stylecheck}

\subsection{Run a style checker}

Let's try and run a style checker~:
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn checkstyle:checkstyle
\end{lstlisting}
We get plenty of errors with the default style \verb?sun_checks.xml?.

Our coding style is closer to Google style than it is to Sun style.

\subsection{Run Google style checker}

Try running with Google checks (provided by the plugin)
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn checkstyle:checkstyle -Dcheckstyle.config.location=google_checks.xml
\end{lstlisting}
NOTE~: this can also be achieved by adding the following lines to your pom.xml~:
\begin{lstlisting}
  <properties>
    <checkstyle.config.location>checkstyle-test.xml</checkstyle.config.location>
  </properties>
\end{lstlisting}

It's getting better but we might want to make a few changes to this default behaviour.

\section{Exercice 5}

\subsubsection{TODO~:}

\begin{itemize}
\item Retrieve a local copy of google checks
\begin{lstlisting}[breaklines=true]
$ wget https://raw.githubusercontent.com/checkstyle/checkstyle/18f6ebbcad23e88e3ae30fc79be464b8b7772a0d/google_checks.xml
\end{lstlisting}
\item  Modify the file \texttt{google\_checks.xml} so that it accepts single character parameter names.
\item You may also consider removing trailing underscores from data members or amending \texttt{checkstyle.xml}
\end{itemize}

\section{Integrate checkstyle to your reporting local website}

Add the following to the file \texttt{pom.xml}
\begin{lstlisting}
  <reporting>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-checkstyle-plugin</artifactId>
        <version>2.16</version>
      </plugin>
    </plugins>
  </reporting>
\end{lstlisting}

The check style report is now included in the build life cycle (\textbf{\texttt{site}} phase).

\subsubsection{TODO~:}

\begin {itemize}
\item Generate the report~:
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn site
\end{lstlisting}
\item Use your favorite WEB browser (firefox, chrome, iceweasel, \...) to visualize the generated report~:
\begin{lstlisting}
$ firefox target/site/project-reports.html &
\end{lstlisting}
\end{itemize}

\section{Exercice 5bis - Checkstyle Report on Jenkins}

\subsubsection{TODO~:}
\begin{itemize}
\item Go back to your item's configuration page and add \\
\texttt{checkstyle:checkstyle -Dcheckstyle.config.location=google\_checks.xml} to your build's \textbf{\texttt{Goals and options}}
\item Check the \textbf{\texttt{Publish Checkstyle analysis results}} box in \textbf{\texttt{Build Settings}}
\item Save and Run the test
\item Check the output~: in the \textbf{\texttt{Build History}} on the left, click on the last build, you should have a new entry named \textbf{\texttt{Checkstyle Warnings}}, have a look at it
\end{itemize}

\clearpage



%----------------------------------------------------------------------------------------
%   PYTHON
%----------------------------------------------------------------------------------------
\begin{homeworkProblem}[Python Exercice]

\section{Local Test Part}

\subsection{Preamble}

In this exercice, you will learn how to install your python program with
packaging tools, test it, measure the tests code coverage, and perform some
static code analysis. And finally do this in a single command for multiple
python versions and environments.


\subsubsection{Tools presentation}

For this you will use the following tools~:

\texttt{setuptools} packages your project,
\texttt{unittest} to write tests (standard library),
\texttt{nose} tools run tests and format the results,
\texttt{mock} allow replacing function or objects during tests,
\texttt{pylint} provide static code analysis and style checking,
\texttt{pep8} verifies code compliancy to python PEP8 style convention
and \texttt{tox} is a virtualenv based test automation tool.


\subsection{Setup}

\subsubsection{Python requirements}

For the exercices you need to install first the following dependencies.
The other test dependencies will be installed during the exercices.


\subsubsection{Create and clone your personal copy of the repository}
First, you will create your personal \texttt{git} repository on the INRIA forge as a branch of the main repository for the \texttt{tpcisedra} project~:
\begin{itemize}
\item Go to \url{https://gforge.inria.fr/projects/tpcisedra/}
\item Click on the \textbf{\texttt{CODE SOURCE}} or \textbf{\texttt{SCM}} tab
\item Click on \textbf{\texttt{Create a personal repository}}
\item Back to the \textbf{\texttt{SCM}} tab, look for the command to access your personal repository.
\end{itemize}

\textbf{WARNING~: do not use the anonymous access (containing \texttt{anonscm}) }


Then on a terminal, clone the content of your personnal \texttt{git} repository. The correct command should look like this~:
\begin{lstlisting}
$ git clone git+ssh://<yourlogin>@scm.gforge.inria.fr/gitroot/tpcisedra/
    users/<yourlogin>.git
$ cd <yourlogin>/python
\end{lstlisting}

You should have retrieved the following file tree~:
{\centering\small
  \begin{minipage}[t]{0.3\linewidth} \small
    \dirtree{%
        .1 tpcisedra/python.
        .2 sphere.
        .2 tp\_ci\_sed.
        .3 \_\_init\_\_.py.
        .3 sphere.py.
        .3 test.
        .4 \_\_init\_\_.py.
        .4 sphere\_test.py.
        .2 raw.
        .3 \#file used later.
    }
\end{minipage}
}
\subsection{Project presentation}

This project should be the best package providing sphere volume computation.
As simple as it can be, we want it packaged, tested, and we want to have this
nice \verb=build|passing= icon on \texttt{github}~: \includegraphics[height=10pt]{build_passing}.

It has a package, named \texttt{tp\_ci\_sed}, with a \texttt{sphere} submodule
and even a cli script to run it.

\subsubsection{Exercice 1}

Try the \texttt{sphere} script.

\subsubsection{Exercice 2}

Write the \texttt{Sphere.volume} method.
For that, use \texttt{math} module and remember volume formula
$ 4 * \Pi * R^3 / 3 $ you learned in school
\footnote{Volume of a $1.5$ radius sphere is around $14.137$}.

\paragraph{} Commit your code with a meaningfull message an push.

\subsubsection{Releasing your code}

Now, is your package ready to use by everyone? Can it be installed by users?


\subsection{Packaging your code}

First step of an integration process is being able to install the project with
its dependencies. In Python it's done using a \texttt{setup.py} script
written with \texttt{setuptools}
\footnote{Default \texttt{setup.py} package is \texttt{distutils} but it
does not manage automatic dependency installation}.

The script simply calls \texttt{setuptools.setup} function with the package
description~: package diretory, name, description, author, license, version,
dependencies, supported python versions, \dots


\subsubsection{Usage}

This \texttt{setup.py} script is the entry point for installing and releasing
your code. It will also be used later as an entry point for tests scripts.

\begin{lstlisting}
$ python setup.py <command> [opts]

# Install the package
$ python setup.py install

# Install the package in a way that lets you edit the sources
$ python setup.py develop

# Upload your last revision to \texttt{PyPi} repository
$ python setup.py upload
\end{lstlisting}

\paragraph{Setuptools Documentation}
\url{https://pythonhosted.org/setuptools/setuptools.html}

\subsubsection{Writing the \texttt{setup.py} script}

Writing the script is basically just giving the right informations in the right
format. Usually adapting an existing one is simple enough so it is provided in
this exercise.

Copy the \texttt{first} script from the \texttt{raw} folder as \texttt{setup.py}.
\begin{lstlisting}
$  cp raw/first setup.py
$  cat setup.py
#! /usr/bin/env python
# -*- coding:utf-8 -*-

import os
from setuptools import setup, find_packages
...
\end{lstlisting}

\subsubsection{Exercice 3}
Open the \texttt{setup.py} script and look at the \texttt{setup} function
arguments.


\paragraph{Package dependency}
Instead of writing in a README what packages are required by your project,
they can be automatically at package installation with \texttt{setuptools}.
Dependencies should be listed in the \texttt{install\_requires} here
\texttt{argparse} will be installed with the package.

\begin{lstlisting}
setup(
    ...,
    install_requires=['argparse'],
)
\end{lstlisting}

Depending on your needs, you can specify the version with \texttt{==, <, !=} operators.

\begin{description}
\item[Note]
By default \texttt{setuptools} uses PyPi to find packages but can be configured
to install from many places, like an existing \texttt{git} repository or an \texttt{http} url
\footnote{\url{https://pythonhosted.org/setuptools/setuptools.html\#dependencies-that-aren-t-in-pypi}}.
\end{description}


\paragraph{Package version} Python package version is usually accessible
at \texttt{package\_name.\_\_version\_\_} and should be consistent with the
version in \texttt{setup.py} .

Importing the package in \texttt{setup.py} script is a source of import
and code coverage errors
\footnote{Don't import your package in \texttt{setup.py}
\url{https://stackoverflow.com/q/11279096/395687}}.

To prevent that, package \texttt{\_\_init\_\_.py} file can be read and parsed
manually to find the version.

\paragraph{}
Package version can be queried with~:
\begin{lstlisting}
$ python setup.py --version
\end{lstlisting}


\subsubsection{Exercise 4}

Find where the version is stored and how it is retrieved in the
\texttt{setup.py} script.

\subsection{Semantic versioning}

Versioning should help users follow features addition and know when incompatible
changes have been introduced.
Semantic Versioning gives you simple rules for changing your version numbers.

\begin{quote}
\begin{center}Summary \url{http://semver.org/}\end{center}

Given a version number MAJOR.MINOR.PATCH, increment the~:

\begin{itemize}
	\item MAJOR version when you make incompatible API changes,
	\item MINOR version when you add functionality in a backwards-compatible manner, and
	\item PATCH version when you make backwards-compatible bug fixes.
\end{itemize}
Additional labels for pre-release and build meta-data are available as extensions to the MAJOR.MINOR.PATCH format.
\end{quote}

For the following parts, remember to increment the version when you change the
API. However, as the code is still in \texttt{alpha} no need to increment the
\texttt{MAJOR} the \texttt{MINOR} is enough.


\subsection{Tests}

Executing your code in command line and visually verifying the result is testing.
However some parts of the code may be hard to reach from the \texttt{cli}, and are hard to
test this way. Also, we want to automate this step and make it repeatable.

So basically, we will write code to execute our code and verify the output.
And to simplify the organization we will use existing tools to write them.

\paragraph{}In this section you will write tests using \texttt{unittest} and
execute them with \texttt{nosetests}.

Install the \texttt{nose} tools dependencies~:
\begin{lstlisting}
$ sudo -H pip install --upgrade  nosetests nose-xcover
\end{lstlisting}

One test has already been written as an example. Run it with \texttt{nosetests}
\begin{lstlisting}
$ nosetests -v
test_volume_0 (tp_ci_sed.test.sphere_test.TestSphere) ... ok

----------------------------------------------------------------------
Ran 1 test in 0.006s

OK
\end{lstlisting}

Now go in \texttt{tp\_ci\_sed/test/sphere\_test.py} to see the implementation.

\paragraph{unittest}
framework\footnote{\url{https://docs.python.org/2/library/unittest.html}}
is the Python implementation of \texttt{JUnit}.

It provides a \texttt{TestCase} base class to help writing tests.
This class implements several assert functions and also runs \texttt{setUp} and
\texttt{tearDown} methods before and after each tests if implemented.
This helps configuring a test environment.


\subsubsection{Exercise 5}

As you can see, \texttt{test\_volume\_0} is not enough to validate your code.
Add another test to validate the volume computation with
$radius=1.5$ where $volume=14.137166941154069$.

\paragraph{}Commit your code with the new test.


\subsubsection{Re-factoring}

Now that your code is tested, you can safely start re-factoring it.
In our formula, the $ 4 * \Pi / 3 $ part can be computed only once instead of
at each \texttt{volume} call.

\subsubsection{Exercise 6}

Move it in a class variable and use it in the \texttt{volume} method.

Run the tests again. It should fail~:

\begin{lstlisting}
$ nosetests -v
test_volume_0 (tp_ci_sed.test.sphere_test.TestSphere) ... ok
test_volume_1_5 (tp_ci_sed.test.sphere_test.TestSphere) ... FAIL

======================================================================
FAIL: test_volume_1_5 (tp_ci_sed.test.sphere_test.TestSphere)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ".../tp_ci_sed/test/sphere_test.py", line 19, in test_volume_1_5
    self.assertEqual(14.137166941154069, vol)
AssertionError: 14.137166941154069 != 14.137166941154067

----------------------------------------------------------------------
Ran 2 tests in 0.007s

FAILED (failures=1)
\end{lstlisting}

\begin{description}
\item[Note] If it does not fail, ask for help, magic numbers technique failed.
\end{description}

Why does the test fail?

Because of floating point arithmetics \emph{rounding errors}.

Our response to this issue strongly depends on what kind of application we are
working on~:
\begin{itemize}
\item In some cases, we want to be aware that something has changed, even when
    the change is the tiniest. In that case, the test we already have is just what we want.
\item In other cases, we need not worry about such a small difference and hence
    do not want to be bothered by tests complaining.
\end{itemize}

Here, the code result is correct, so the fail should pass.

\subsubsection{Exercice 7}

Find a way to modify the test so small rounding differences do not cause errors.

\paragraph{Hint}List of \texttt{unittest} assert functions~:

\url{https://docs.python.org/2/library/unittest.html\#unittest.FunctionTestCase}


\subsection{Code coverage}

When running tests, the information of what part of the code has been tested is
also meaningful. It is often refered as "code coverage".

With Python it can be generated with the \texttt{coverage} package, but also
directly with \texttt{nosetests} and \texttt{nose-xcover}.

To get the coverage output, run
\begin{lstlisting}
$ nosetests -v --with-xcoverage --cover-erase  --cover-inclusive \
    --cover-branches --cover-html --cover-package  tp_ci_sed

test_volume_0 (tp_ci_sed.test.sphere_test.TestSphere) ... ok
test_volume_1_5 (tp_ci_sed.test.sphere_test.TestSphere) ... ok

Name                  Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------
tp_ci_sed.py              1      0      0      0   100%
tp_ci_sed/sphere.py      19      6      2      1    67%   19, 28-32, 36, 35->36
-----------------------------------------------------------------
TOTAL                    20      6      2      1    68%
----------------------------------------------------------------------
Ran 2 tests in 0.012s

OK
\end{lstlisting}

You can read the coverage output directly in the \texttt{nosetests} output.
But a human readable \texttt{html} report and an \texttt{xml} report for \texttt{Jenkins} are also generated.


\begin{lstlisting}
$ ls
cover coverage.xml  raw  sphere  tp_ci_sed
 file coverage.xml
coverage.xml: XML document text
\end{lstlisting}

See the \texttt{html} report

\begin{lstlisting}
$ firefox cover/index.html &
\end{lstlisting}


\subsection{\texttt{setup.py} sub-commands}

As running \texttt{nosetests} with all the options is quite a pain, you will use
\texttt{setuptools} to configure the \texttt{nosetests} command.

Calling \texttt{nosetests} can be done using
\begin{lstlisting}
$ python setup.py nosetests

...

reading manifest file 'tp_ci_sed.egg-info/SOURCES.txt'
writing manifest file 'tp_ci_sed.egg-info/SOURCES.txt'
..
----------------------------------------------------------------------
Ran 2 tests in 0.006s

OK
\end{lstlisting}

Configuring \texttt{setup.py} commands requires adding options in a
\texttt{setup.cfg} file.

Copy the \texttt{second} script from the \texttt{raw} folder as \texttt{setup.cfg}.
\begin{lstlisting}
$ cp raw/second setup.cfg
$ cat setup.cfg
\end{lstlisting}

The first part is \texttt{nosetests} configuration and allow coverage and also
searching for all type of tests.

Re run the command~:
\begin{lstlisting}
$ python setup.py nosetests

...

----------------------------------------------------------------------
XML: /home/harter/work/tpcisedra/python/nosetests.xml
Name                  Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------
tp_ci_sed.py              1      0      0      0   100%
tp_ci_sed/sphere.py      19      6      2      1    67%   19, 28-32, 36, 35->36
-----------------------------------------------------------------
TOTAL                    20      6      2      1    68%
----------------------------------------------------------------------
Ran 2 tests in 0.012s

OK
\end{lstlisting}


Now running the tests with \texttt{python setup.py nosetests} also generates the
coverage report.


\subsection{Code static analysis and style}

Python is a dynamic language where many things are evaluated at run-time,
more than compiled languages. It means that if you do typos, errors may only
occur when running the program. Using a static analysis program can detect
errors without executing your program.

With the same goal, using coding standards for formatting your code can increase
readability. It make all your code look the same and ease comprehension.
For python there is even an official coding style guide defined in the
Python Enhancement Proposal 8 (PEP8\footnote{\url{https://www.python.org/dev/peps/pep-0008/}}).


\paragraph{}In this section you will use two tools~:
\texttt{Pylint} and \texttt{PEP8} to perform static analysis and code style
checking. They will be run using the \texttt{setup.py} script and so there
configuration is in \texttt{setup.cfg}.


Install dependencies, note the \texttt{setuptools-XXXX} which provide
\texttt{setup.py} wrapper.
\begin{lstlisting}
$ sudo -H pip install --upgrade  pylint pep8 setuptools-lint setuptools-pep8
\end{lstlisting}

Run the two commands~:
\begin{lstlisting}
$ python setup.py lint
$ python setup.py pep8
\end{lstlisting}

You will, I think, get a lot of errors and warnings.

\subsubsection{Exercice 8}

Fix the errors.
However, putting an empty docstring to get rid of the message is evil, it is
your code documentation!

\begin{description}
  \item[Note] The tools may return some false-positive.
    In this case it is possible to disable the error message.
    Refer to the documentation when needed~:
    \url{http://docs.pylint.org/message-control}
\end{description}


\subsection{All tests in one command}

Now that we sum up what we have, testing all your application with the previous
tools is simply running the three following commands~:

\begin{lstlisting}
$ python setup.py nosetests
$ python setup.py lint
$ python setup.py pep8
\end{lstlisting}

You can write that in your documentation and let other users to do it.
Is it enough?

Do you remember to tell to install the tests dependencies?
And if you want to add another test tool? You must inform all developers to
run the new command.
And if you want to test with Python3 ?

Adding a bash script to do it would work but as we are working with Python,
let's use the right tool.


\paragraph{tox}\footnote{\url{https://tox.readthedocs.org/en/latest/}}
Is a generic \texttt{virtualenv} based automation tool.
It lets you test that your package installs with different interpreters and runs
tests in each environment.

Install \texttt{tox} dependency.
\begin{lstlisting}
$ sudo -H pip install --upgrade  tox
\end{lstlisting}


\paragraph{}
First thing, copy the \texttt{tests\_utils} from \texttt{raw} directory~:
\begin{lstlisting}
$ cp -r raw/tests_utils .
$ ls tests_utils/
coverage-python-3.2.txt  pylint-python-2.6_3.2.txt  test-requirements.txt
\end{lstlisting}

Look into these files.

All tests dependencies are described in the \texttt{test-requirements.txt} file.
The two other files are specific versions for python 2.6 and 3.2.


Now copy the \texttt{tox.ini} file from \texttt{raw/third} file.
\begin{lstlisting}
$ cp -r raw/third tox.ini
\end{lstlisting}

\clearpage
The file content is the following~:
\lstinputlisting[caption=tox.ini,label=tox.ini]{../../Src/Python/tox.ini}

The different part of the file are~:
\begin{itemize}
\item \texttt{envlist}~: is the list of python version you want to run on. Here only Python2.7 for the moment.
\item \texttt{deps}~: the test dependencies. With specific packages versions for \texttt{python2.6 python3.2}.
\item \texttt{commands}~: the list of test commands. The front dash \texttt{-} means don't fail on execution error.
\end{itemize}

Now executing your tests simply means running \texttt{tox} and the only required
dependency installed is \texttt{tox} itself.

\paragraph{Other versions}
If everything succeeds, and you have \texttt{python3} installed add it to the environment
to see the result (\texttt{py32} for python3.2). Re-run \texttt{tox}.
I think it will fail, at least with the 'print' statement.

However, you see how easy it is to test your code on different python versions.
Making a code working for \texttt{python2} and \texttt{python3} requires some time, but at least
it's easy to test!

\paragraph{Conclusion} Now all you learned was how a test environment is created,
how it is problematic, but how it can, at the end be summed up in one command
with \texttt{tox}.



\subsection{Advances tests writing~: mocking}


\begin{description}
    \item[mock] \url{http://www.voidspace.org.uk/python/mock/index.html}
\end{description}

When testing, it is useful to replace some part of your application to give it
a special behavior, like raising an exception, or to prevent its side effect,
like connection to an external service. It is also easier to be able to know how
an object has been used or a function been called.

In this section you will see \texttt{mock} to test the \texttt{main} function
and verify the printed output.


Install the dependency to have it on your system. It will be installed by
\texttt{tox} in the test environment.
\begin{lstlisting}
$ sudo -H pip install --upgrade  mock
\end{lstlisting}

\texttt{mock} class provides mainly two important things~:
\begin{itemize}
    \item \texttt{Mock} class which is an object whose behaviour can be
        configured and that records all action on it.
    \item \texttt{patch} function that dynamically replaces one
        function/method/object with a Mock object.
\end{itemize}

\paragraph{sorry}Explaining mocks and applying is too long for this course,
in this section I will mainly make you copy paste the code, try it and read
afterwards to give you an example. See online documentations when trying it
yourself.

Copy the \texttt{fourth} file as \texttt{tp\_ci\_sed/test/sphere\_test\_main.py}
and re-run tests.
\begin{lstlisting}
$ cp -r raw/fourth tp_ci_sed/test/sphere_test_main.py
$ tox
\end{lstlisting}

You can see that we now have 100\% coverage.

Now open the \texttt{sphere\_test\_main.py} in your editor and I will detail
some parts.

\paragraph{Main function} In order to test the main function, the program
arguments \texttt{sys.argv} should be replaced with different values.
Here I am patching it using a \texttt{context\_manager} (\texttt{with} keyword).
It automatically applies and cleans up the patch.

\paragraph{Mocking outputs} Two methods are presented~:

The first one is mockng \texttt{sys.stdout} with a \texttt{StringIO} object and
get the written string. Here it is also done using a context manager.

Another, is mocking the file object and verify \texttt{write} call arguments.
It is presented here for \texttt{sys.stderr} by patching in \texttt{setUp} and
cleaning it with \texttt{patch.stopall()} in \texttt{tearDown}.


Both method are valid, it's just for presenting alternatives.


\paragraph{Hints~:} Some advices I want to give on patch~:

\begin{itemize}
\item When 'patching' always verify that the mock has been called by your
 program, there are so many cases where you can just fail to patch correctly.
\item When patching a class, you should use MockClass.return\_value to get the instance mock.
\item The patching path can depend on how the module is imported
    \url{http://www.voidspace.org.uk/python/mock/patch.html#where-to-patch}.
    Read it, try it, and understand this prior testing your application.
    Basically, when patching an object imported using \texttt{import XXXX} it requires absolute patch path.
    And when an object imported using \verb=from XXX import yyyyy= it requires patching from the importing module.
\end{itemize}

For every other problems, look at the documentation.


\section{Continuous Integration Part}
\subsection{Validate on CI}

At this point you have a your python project packaged with setup.py and tests
running managed by tox. This means that running your tests only need to run~:

\begin{lstlisting}
$ tox
\end{lstlisting}

\subsection{Running your first test on CI}

\begin{itemize}
\item Create your job with \texttt{New Item} button on the left menu.
\item For Python create a \texttt{Freestyle project} and put a name without spaces, it always
brings errors in scripts to have path with spaces.
\item Then go to \texttt{Configure}.
\end{itemize}

\subsubsection{Git configuration}

\begin{itemize}
\item Go to \textbf{\texttt{Source Code Management}} and choose \texttt{Git}
\item Put the anonymous \texttt{git} url of the repository \url{https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<yourlogin>.git}
\item Select your branch name \texttt{*/branch\_name}.
\end{itemize}

\subsubsection{Build Step}

\begin{itemize}
\item Add build step~: \texttt{Execute Shell} and execute~:
\begin{lstlisting}
$ cd python/
$ tox
\end{lstlisting}
\item Save the configuration.
\end{itemize}

\subsubsection{Running test}

What is the result ?

See \texttt{Console Output} to see the script execution.

\subsection{Fixing the errors the Python way}

As seen, \texttt{tox} is not installed on the build machine. It can either be installed
manually or as a step of the integration process. The last solution is more in
the process of \emph{integration} but sometimes you don't have the choice.

\begin{itemize}
\item Remove the build step and replace it with \texttt{Virtualenv Builder}.
This puts the code execution in a separated python environment for the build.
\item Now as first step, install your \texttt{tox} dependency~:
\begin{lstlisting}
$ pip install --quiet --upgrade tox
$ cd python
$ tox
\end{lstlisting}
\item Save and build, it should be a successful build.
\end{itemize}

See the build output, you can see tests/coverage/pylint/pep8 text results.


\subsection{Adding build feedback}

A big value of \texttt{Jenkins} is the ability to nicely present your tests results.

The tools used to run tests and code quality where selected because they have output files compatible with \texttt{Jenkins} plugins.

\begin{description}
\item[Note~:]
This selection may look restrictive, but it also means that the tools are indeed used by many developers and that it is
not only a one man written test script.
\end{description}

\begin{itemize}
\item \texttt{nosetests} outputs as a JUnit compatible \texttt{xml}~: \texttt{nosetests.xml}
\item \texttt{nose-xcover} outputs coverage compatible with cobertura~: \texttt{coverage.xml}
\item \texttt{pylint} and \texttt{pep8} output is recognized by 'warnings' and 'violations' plugins.
\end{itemize}

These output parsing is managed in \textbf{\texttt{Add post-build action}}.
%% Maybe print the real plugins names here

\subsection{Add tests results feedback}

\begin{description}
\item[Step \texttt{Publish JUnit test result report}] \hfill \\
\begin{itemize}
\item Test report \texttt{xml}~: `**/*tests.xml` to scan for all files ending with 'tests.xml'
\end{itemize}
\end{description}

\subsubsection{Add coverage feedback}

\begin{description}
\item[Step \textbf{\texttt{Publish Cobertura Coverage Report}}] \hfill \\
  \begin{itemize}
  \item \texttt{Cobertura xml} report pattern~:  \texttt{**/coverage.xml} to scan for all  \texttt{coverage.xml} files.
  \end{itemize}
\end{description}

As source files are not based at root directory \texttt{Cobertura} fails to locate source
files.

A solution is to create a symlink to the source directory~:
\begin{itemize}
  \item Add a build step \texttt{Execute shell} with~:
\begin{lstlisting}
# Hack to help cobertura find source files
$ ln  -nfs python/tp_ci_sed  tp_ci_sed
\end{lstlisting}
\end{itemize}

\subsubsection{Add code quality output}

\begin{description}
\item[Step \texttt{Scan for compiler warnings}] \hfill \\
  \begin{itemize}
  \item Scan console log add two parsers, one for \texttt{pylint} and another for \texttt{pep8}.
  \item In advanced configuration, select \textbf{\texttt{Resolve relative paths}}, either the plugin doesn't find the source files as they are not in the root folder.
  \end{itemize}
\end{description}


\subsubsection{Code review by ChuckNorris}

\begin{description}
\item[Step \texttt{Activate Chuck Norris}] \hfill \\
It displays you Chuck Norris facts and a picture of Chuck adapted to your build result (seems like the picture is not displayed why ?)
\end{description}


Do not forget to save configuration.


\subsection{Analyze build output}

\begin{itemize}
\item Build the project two times to get a nice displayed output. Plugins need
multiple builds to create graphs.
\end{itemize}


\subsection{Coverage Report}

\begin{itemize}
\item Click on Coverage Report, you can then see per file coverage output.
\end{itemize}


\subsection{Pylint/PEP8}

\begin{itemize}
\item Click on \textbf{\texttt{Pylint/PEP8}} reports and see the errors in the source files.
\end{itemize}



\subsection{Further steps}

%% TODO

Automatically run the build~:
\begin{itemize}
\item  Never~: you only run it manually (not recommended)
\item Periodically~: Every night at 3AM may be enough if your code moves slowly
\item At each commit~: with repository polling/ with \texttt{git} hook (see how...)
\end{itemize}

Send mails on build failure~:
\begin{itemize}
\item  How to do that ?
\end{itemize}


\subsection{Improvements}

\begin{itemize}
\item Try fixing all your code to get perfect results outputs;*
\item Use \texttt{tox} to run tests on \texttt{python3} also and make your code compatible with.
\end{itemize}

%%\lipsum[1]

%%Listing \ref{Sphere} shows a Java program.
%%\javascript{Sphere}{Sample Java program with Highlighting}

%%Another program example for Python
%%Listing \ref{Python_example} shows a Python program.
%%\pythonscript{Python_example}{Sample Python program with highlighting}


\end{homeworkProblem}


\clearpage
%----------------------------------------------------------------------------------------
%   C++
%----------------------------------------------------------------------------------------
%"${)

\begin{homeworkProblem}[C++ Exercise]

\section{Preamble}

In this exercise, we will focus on the configuration of Jenkins for~:
\begin{enumerate}
\item a simple aspect of c++ unit testing, 
\item an aspect of dynamic testing~: source coverage,
\item a demonstration of static analysis with \texttt{cppcheck}.
\end{enumerate}

To perform this \texttt{C++} exercise, we rely on three main development tools~:

\begin{itemize}
\item A \texttt{C++} compiler, for example \texttt{GNU C++} or \texttt{clang}.
\item A build process manager~: \texttt{CMake} 
\item A testing framework~: \texttt{cppunit}
\item A static analysis tool~: \texttt{cppcheck}
\item Coverage analysis tools~: \texttt{gcov}, \texttt{lcov} \texttt{gcvor}.
\end{itemize}

On Linux, BSD, MACOS X systems, suitable versions may simply be installed with the package manager (\texttt{yum, apt, etc}).

For example~: 
\begin{itemize}
\item on Fedora systems, one may use the command~: \texttt{sudo yum install cmake gcc-c++ cppunit cppcheck gcov lcov}
\item on recent Debian or Ubuntu systems~:
\texttt{sudo apt-get install cmake gcc-c++ cppunit cppcheck gcov lcov}
\end{itemize}

For \texttt{gcovr}, use \texttt{sudo pip install gcovr}.

\section{Unit testing}
\subsection{Local setup}

\subsubsection{Clone the git repository from INRIA forge and create your own branch}
First, you will create your personal \texttt{git} repository on the INRIA forge as a branch of the main repository for the \texttt{tpcisedra} project~:
\begin{itemize}
\item Go to \url{https://gforge.inria.fr/projects/tpcisedra/}
\item Click on the \textbf{\texttt{CODE SOURCE}} or \textbf{\texttt{SCM}} tab
\item Click on \textbf{\texttt{Create a personal repository}}
\item Back to the \textbf{\texttt{SCM}} tab, look for the command to access your personal repository.
\end{itemize}

\textbf{WARNING~: do not use the anonymous access (containing \texttt{anonscm}) }


Then on a terminal, clone the content of your personal \texttt{git} repository. The correct command should look like this~:
\begin{lstlisting}
$ git clone \
  git+ssh://<yourlogin@scm.gforge.inria.fr/gitroot/tpcisedra/users/<yourlogin>.git
$ cd tpcisedra/cxx
\end{lstlisting}

A minimal \texttt{CMake} project is present under the file tree~:\\
{\centering\small
            \begin{minipage}[t]{0.3\linewidth}
\dirtree{%
  .1 tpcisedra/cxx.
  .2 CMakeLists.txt.
  .2 cmake.
  .3 TP.cmake.
  .2 Sphere.hpp.
  .2 Sphere.cpp.
  .2 bench.cpp.
  .2 tests.
  .3 CMakeLists.txt.
  .3 TestTP.hpp.
  .3 TestTP.cpp.
  .3 TestMain.cpp.
}
\end{minipage}
}


This \texttt{CMake} project provides the framework needed to build and test a
dynamic shared and versioned \textbf{\texttt{TP}} \footnote{\textbf{\texttt{TP}} for \textbf{\texttt{Travaux Pratiques}}
  in french} library. The \texttt{CMake} configuration is specified in two
\texttt{CMakeLists.txt} files~:
\begin{itemize}
\item one under the main directory~: the main \texttt{CMakeLists.txt}
\item one under the \texttt{tests} directory.
\end{itemize}

The API provided by this library is at this level composed by a single \texttt{Sphere} class. The \texttt{Sphere} class offers an object constructor with the \texttt{radius} as parameter and a \texttt{volume} method.

A benchmark program named \texttt{bench.cpp} is also built and linked with the
library. Although the computation is very simple, this benchmark program may
be used to compare the influence of some compiler optimization flags.

\subsubsection{Check that you can build the project and run the test}

On a Unix system~:
\begin{itemize}
\item Create a build directory
\item Create the build environment with \texttt{CMake}
\item Build the project
\item Run the test
\end{itemize}


\begin{lstlisting}
$ mkdir build
$ cd build
$ cmake ..
$ make
$ make test
\end{lstlisting}

%$

\subsubsection{Run the benchmark}

\texttt{CMake} provides pre-defined build configuration that may be chosen
with the \texttt{CMAKE\_BUILD\_TYPE} variable. Among them we are going to
consider~:

\begin{itemize}
\item the \texttt{Debug} build type which sets the debug flags (\texttt{-g} with \texttt{GNU C++}) 
\item the \texttt{Release} build type which sets some optimization flags (\texttt{-O3 -DNDEBUG} with \texttt{GNU C++})
\end{itemize} 

Once a directory has been given as argument to \texttt{CMake} it remains in a
cache, the \texttt{CMakeCache.txt} file in your build directory. This cache
file is a text file and may be edited by hand.

So for next calls to \texttt{CMake}, we can use the dot directory as argument~:

\begin{lstlisting}
$ cmake .
\end{lstlisting}

%$

\texttt{CMake} variables may be set on the command line with \texttt{-D}
arguments~: 
\begin{lstlisting}
$ cmake . -D<VARIABLE\_NAME>=<VALUE>
\end{lstlisting}

The value remains in the cache file, so when a variable has been modified once with a call to cmake, it is not necessary to define its value anymore on the command line.

Let's configure our build to a debug build~:
\begin{lstlisting}
$ cmake . -DCMAKE_BUILD_TYPE=Debug
$ make
$ ./bench
\end{lstlisting}

For an optimized build, we do~:
\begin{lstlisting}
$ cmake . -DCMAKE_BUILD_TYPE=Release
$ make
$ ./bench
\end{lstlisting}

Over this very simple computation, the benchmark difference between Debug and
Release is not dramatic.

With \texttt{GNU C++} compiler, we can go beyond \texttt{-O3} optimization flag with the
\texttt{fast-math} option, which implies \texttt{-funsafe-math-optimizations}
and may break some of the requirements of \texttt{IEEE} and \texttt{ANSI}
standards.

To pass a specific argument to the \texttt{GNU C++} compiler, we use the variable \texttt{CMAKE\_CXX\_FLAGS}. The arguments passed on the command line to this
variable are added to the other compiler arguments. In doubt with the
generated specification, one can use the argument \texttt{VERBOSE=1} to make,
in order to see the flags passed to the compiler.

\begin{lstlisting}
$ cmake . -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=-ffast-math
$ make VERBOSE=1
$ ./bench
\end{lstlisting}

%$

You should see a difference on time.

Now, let's keep this configuration in our build directory.

\clearpage
\subsection{Jenkins setup}

Log into the project's \texttt{Jenkins} instance~:

\begin{enumerate}
\item Connect to the INRIA Continuous Integration web portal~: \url{https://ci.inria.fr/}.

\item Log in and click \textbf{\texttt{Dashboard}} in the top menu
\item You should have been added to project \textbf{\texttt{TPCISedRa}}, click on the \textbf{\texttt{Jenkins}} button.
You may be prompted to log into \texttt{Jenkins}, use the same login/passwd as for the ci portal.
\end{enumerate}

Running your first test on CI~:
\begin{itemize}
\item From our \texttt{Jenkins} dashboard page (\url{https://ci.inria.fr/tpcisedra/}), click \textbf{\texttt{New Item}} in the menu on the left
\item Provide a name for this new item (avoid spaces since it is likely to lead to errors) and select \textbf{\texttt{Freestyle project}}
\end{itemize}


\texttt{Git} configuration~:
\begin{itemize}
\item In the new item's configuration page (which you will be redirected to after clicking \textbf{\texttt{OK}}), choose \texttt{Git} as your \textbf{\texttt{Source Code Manager}}
\item Copy the \emph{anonymous} URL to your personal repository into the appropriate field~:

\begin{lstlisting}
https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<yourlogin>.git
\end{lstlisting}
\end{itemize}

An important step for the continuous integration step is the build trigger.

A simple possibility is to choose to build periodically, this is
suitable for some nightly or weekly tests that may be time consuming
and are not meant to be launched after each commit, but this should be
avoided for short periods.  In our case, we want the results to be
displayed as soon as possible so we choose to launch the build after a
post-commit hook~:

\begin{itemize}
\item Click on \textbf{\texttt{Poll SCM}}
\item In the \textbf{\texttt{Schedule}} field, cut and paste~:\\ 
\texttt{\# Leave empty. We don't poll periodically, but need polling enabled to let HTTP trigger work}
\end{itemize}

Then on the INRIA gforge server, create the post-commit hook \texttt{post-receive}~:

\begin{lstlisting}
$ ssh <your gforge login>@scm.gforge.inria.fr
$ cd /gitroot/tpcisedra/users/<your gforge login>.git/hooks
\end{lstlisting}

And then create the executable file \texttt{post-receive}~:
\begin{lstlisting}[breaklines=true]
$ #!/bin/sh
wget --auth-no-challenge --no-check-certificate
http://ci.inria.fr/tpcisedra/git/notifyCommit?url=https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<your gforge login>.git
\end{lstlisting}

%$

\subsubsection{Exercise 1}

Add a new build step~ using \texttt{Execute shell}, where you inform \texttt{Jenkins} how to build and test the project.

\begin{itemize}
\item You have to choose the \texttt{Debug} configuration for this build, this will be needed for coverage as we will see later.\\
In the shell working directory (the result of the command \texttt{/bin/pwd} in
this shell) \texttt{Jenkins} has cloned your source directory.
\item Then save the project and verify the configuration with a click on \textbf{\texttt{Build
Now}} in the menu on the left.
\item In the \texttt{Build History} on the left, click on the last build (hopefully \#1), then select \texttt{Console Output}.\\
You can also check the \texttt{Test Result}.
\end{itemize}

\subsubsection{Exercise 2}

\paragraph{First part}
Edit the implementation of the \texttt{Sphere} class~:
\texttt{tpcisedra/c++/src/Sphere.cpp} and have a look at the code of the method \texttt{Sphere::volume()}.

\begin{lstlisting}
double Sphere::volume() const
{
  return 4 * M_PI * pow (this->_radius, 3.) / 3.;
}
\end{lstlisting}

This is the method which is tested in the unique test of the library, and the test is implemented in the file~:

\texttt{tpcisedra/c++/src/tests/testTP.cpp}

Let's imagine we want to improve the efficiency of the \texttt{volume()}
method by pre-computing the value \verb?4 * Math.PI / 3?

TODO~:
\begin{itemize}
\item Extract this value into a class data member.
\item Run the benchmark. This may shows only a very, very minimal improvement!
\item Run the test.
\end{itemize}

The test may still be successful (this may depends on your hardware and compiler).

Let's assume it is successful and commit your modifications.

\begin{lstlisting}
$ git commit -m "precomputation of 4pi/3"
$ git push
\end{lstlisting}

The test should now fail on \texttt{Jenkins}.

Here is the output you can see on \texttt{Jenkins} console~:
\begin{lstlisting}
+ make test
Running tests...
Test project /builds/workspace/mb-cxx/build
    Start 1: TestVolume
1/1 Test #1: TestVolume .......................***Failed    0.00 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =   0.00 sec

The following tests FAILED:
	  1 - TestVolume (Failed)
\end{lstlisting}

\paragraph{Second part}

The \texttt{-funsafe-math-optimizations} implied by \texttt{-ffast-math}
allows for reordering of floating points operations and this may lead to
different results.

The direct check of equality of floating point numbers with the \texttt{==}
operator should be avoided, we first add a warning (only if understood by the
compiler) in order not to reproduce this kind of error.

Since version $4.6$, \texttt{GNU C++} provides this warning \texttt{-Wfloat-equal}. 
With portability in mind, before adding the flag to the compiler command, we need to check that the compiler accepts it.

With \texttt{CMake}, there is no built-in function for this operation, but that
can be achieved with a simple macro~:

\begin{lstlisting}
include(TestCXXAcceptsFlag)
macro(add_cxx_compiler_flag _flag)
  string(REPLACE "-" "_" _flag_var ${_flag})
  check_cxx_accepts_flag("${_flag}" CXX_COMPILER_${_flag_var}_OK)
  if(CXX_COMPILER_${_flag_var}_OK)
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${_flag}")
  endif()
endmacro()
\end{lstlisting}

This macro is provided in the \texttt{TP.cmake} module file under \texttt{cmake} directory.

To load this TP module, you need to modify the \texttt{CMakelists.txt} file~:
\begin{itemize}
\item Set the \texttt{CMake module path} to this directory~:
\begin{lstlisting}
set(CMAKE_MODULE_PATH ${CMAKE_CURRENT_SOURCE_DIR}/cmake)
\end{lstlisting}
\item Load the module \texttt{TP}; this should be done before using the macro~:
\begin{lstlisting}
include(TP)
\end{lstlisting}
\end{itemize}

%$

On \texttt{Jenkins} side, compiler warnings can be checked in the \textbf{\texttt{Post build Actions}} step of your build project. 

TODO~:
\begin{itemize}
\item In the \texttt{CMake} configuration file, \texttt{CMakeLists.txt}, include the TP module
\item With the provided \texttt{CMake TP} macro, add the compiler warning to the \texttt{CMake} configuration
\item Verify that the warning is printed during compilation
\item Commit the code in order to check the parsing done by \texttt{Jenkins}
\item In \texttt{Jenkins}, add the scan for compiler warnings in the \textbf{\texttt{Post build Action}} of your project
\item Modify the appropriate test in \texttt{TestTP.cpp} so small rounding
  differences do not cause errors, \texttt{cppunit} provides a macro for this~: 
  \texttt{CPPUNIT\_ASSERT\_DOUBLES\_EQUAL(expected, actual, delta)}.
\item Once it is OK and the warning has gone, commit
\item Rebuild on \texttt{Jenkins} to check.
\end{itemize}

%$



%--------------------------------------
\section{Code coverage}

This is a demonstration of some dynamics analysis. After the tests are
executed, the code coverage tools shows which lines of code have been involved
in the execution.

\subsection{Installation}

Coverage with \texttt{gcov} needs the \texttt{GNU C++} compiler and the
\texttt{-fprofile-arcs} and \texttt{-ftest-coverage} options.

\texttt{gcov} generates raw output. We are going to use the \texttt{lcov} utility for the
post-processing and the generation of \texttt{html} pages and the \texttt{gcovr} utility in
order to present parsable results to \texttt{Jenkins}.

A \texttt{CMake} function \texttt{add\_test\_with\_coverage} is provided in the
\texttt{TP} module to simplify the whole setup.

This function, when used in place of the standard \texttt{CMake} function
\texttt{add\_test} function, provides coverage support through a new
\texttt{make coverage} target (You can see all \texttt{make} targets with the help
target~: \texttt{make help})
%$

\subsubsection{Exercise 3}

TODO~:
\begin{itemize}
\item Install coverage for the test routine \texttt{TestVolume}. In the \texttt{CMake} configurations files, you need to set the coverage flags for the build of the library and the test file with the \texttt{add\_cxx\_compiler\_flag}.
\item Run a test with \texttt{make coverage}
\item With a Web browser, open the file \texttt{index.html} under \texttt{TestTP\_\_testVolume} directory.
\item On the \texttt{Jenkins} side, modify the build process in \textbf{\texttt{Execute shell}}. And in \textbf{\texttt{Post-Build Actions}}, add \textbf{\texttt{Publish Cobertura Report}} with the \texttt{Cobertura xml} report pattern set to \texttt{**/coverage.xml}
\item Commit
\end{itemize}

Let's test if it works with more than one class. 

Thanks to another development branch, we add a new class \texttt{Alphabet} to
our project~:
\begin{lstlisting}
$ git merge alpha-cxx
\end{lstlisting}

%$

\subsubsection{Exercise 4}
\begin{itemize}
\item Generate and visualize the corresponding coverage report.
\item Improve the test coverage and commit.
\end{itemize}

%--------------------------------------
\section{Static analysis}

Here the analysis does not need any compilation or execution.
Whereas it is presented last, it may be performed first.

\subsection{cppcheck}

One can simply have a report with the command

\begin{lstlisting}
$ cppcheck <your source directory> -f -q --enable=style 
\end{lstlisting}

%$

The results we obtain depends on the version of \texttt{cppcheck}!

On the virtual machine, the latest (\texttt{1.71}) \texttt{cppcheck} is installed.

\subsubsection{Exercise 5}
\begin{itemize}
\item Install the check on Jenkins. One have to generate an \texttt{XML} output
  (\texttt{--xml} option) and to redirect standard error to a file name
  \texttt{cppcheck-result.xml}). Jenkins read this file if configured properly
  in the ``Post-Build'' Action of your build project.
\item Fix some warnings and commit.
\end{itemize}


\end{homeworkProblem}
%----------------------------------------------------------------------------------------

\end{document}
