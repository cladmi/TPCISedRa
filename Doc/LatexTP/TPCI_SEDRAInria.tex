%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Programming/Coding Assignment
% LaTeX Template
%
% This template has been downloaded from:
% http://www.latextemplates.com
%
% Original author:
% Ted Pavlic (http://www.tedpavlic.com)
%
% Note:
% The \lipsum[#] commands throughout this template generate dummy text
% to fill the template out. These commands should all be removed when
% writing assignment content.
%
% This template uses a Perl script as an example snippet of code, most other
% languages are also usable. Configure them in the "CODE INCLUSION
% CONFIGURATION" section.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{article}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage[usenames,dvipsnames]{color} % Required for custom colors
\usepackage{graphicx} % Required to insert images
\usepackage{listings} % Required for insertion of code
\usepackage{courier} % Required for the courier font
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{hyperref} % For urls
\usepackage{dirtree}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
%\lhead{\hmwkAuthorName} % Top left header
%\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle} % Top center head
\lhead{\hmwkTitle} % Top center head
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \protect\pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs

%----------------------------------------------------------------------------------------
%	CODE INCLUSION CONFIGURATION
%----------------------------------------------------------------------------------------

\definecolor{MyDarkGreen}{rgb}{0.0,0.4,0.0} % This is the color used for comments
\lstloadlanguages{Perl, Java, Python, C++} % Load Perl syntax for listings, for a list of other languages supported see: ftp://ftp.tex.ac.uk/tex-archive/macros/latex/contrib/listings/listings.pdf

\lstset{language=C++, % Use C++
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % functions bold and blue
        keywordstyle=[2]\color{Purple}, % function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=4, % 5 spaces per tab
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=2 % Line numbers go in steps of 5
}
\lstset{language=Java, % Use Java in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % functions bold and blue
        keywordstyle=[2]\color{Purple}, %  function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=4, % 5 spaces per tab
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=2 % Line numbers go in steps of 5
}
\lstset{language=Python, % Use Python in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % functions bold and blue
        keywordstyle=[2]\color{Purple}, % function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=4, % 5 spaces per tab
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=2 % Line numbers go in steps of 2
}

\lstset{language=Perl, % Use Perl in this example
        frame=single, % Single frame around code
        basicstyle=\small\ttfamily, % Use small true type font
        keywordstyle=[1]\color{Blue}\bf, % Perl functions bold and blue
        keywordstyle=[2]\color{Purple}, % Perl function arguments purple
        keywordstyle=[3]\color{Blue}\underbar, % Custom functions underlined and blue
        identifierstyle=, % Nothing special about identifiers
        commentstyle=\usefont{T1}{pcr}{m}{sl}\color{MyDarkGreen}\small, % Comments small dark green courier font
        stringstyle=\color{Purple}, % Strings are purple
        showstringspaces=false, % Don't put marks in string spaces
        tabsize=5, % 5 spaces per tab
        %
        % Put standard Perl functions not included in the default language here
        morekeywords={rand},
        %
        % Put Perl function parameters here
        morekeywords=[2]{on, off, interp},
        %
        % Put user defined functions here
        morekeywords=[3]{test},
       	%
        morecomment=[l][\color{Blue}]{...}, % Line continuation (...) like blue comment
        numbers=left, % Line numbers on left
        firstnumber=1, % Line numbers start with line 1
        numberstyle=\tiny\color{Blue}, % Line numbers are blue and small
        stepnumber=5 % Line numbers go in steps of 5
}

% Creates a new command to include a perl script, the first parameter is the filename of the script (without .pl), the second parameter is the caption
\newcommand{\perlscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.pl}
\end{itemize}
}

\newcommand{\javascript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.java}
\end{itemize}
}

\newcommand{\pythonscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.py}
\end{itemize}
}

\newcommand{\cppscript}[2]{
\begin{itemize}
\item[]\lstinputlisting[caption=#2,label=#1]{#1.cpp}
\end{itemize}
}

%----------------------------------------------------------------------------------------
%	DOCUMENT STRUCTURE COMMANDS
%	Skip this unless you know what you're doing
%----------------------------------------------------------------------------------------

% Header and footer for when a page split occurs within a problem environment
\newcommand{\enterProblemHeader}[1]{
\nobreak\extramarks{#1}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
}

% Header and footer for when a page split occurs between problem environments
\newcommand{\exitProblemHeader}[1]{
\nobreak\extramarks{#1 (continued)}{#1 continued on next page\ldots}\nobreak
\nobreak\extramarks{#1}{}\nobreak
}

\setcounter{secnumdepth}{0} % Removes default section numbers
\newcounter{homeworkProblemCounter} % Creates a counter to keep track of the number of problems

\newcommand{\homeworkProblemName}{}
\newenvironment{homeworkProblem}[1][Problem \arabic{homeworkProblemCounter}]{ % Makes a new environment called homeworkProblem which takes 1 argument (custom name) but the default is "Problem #"
\stepcounter{homeworkProblemCounter} % Increase counter for number of problems
\renewcommand{\homeworkProblemName}{#1} % Assign \homeworkProblemName the name of the problem
\section{\homeworkProblemName} % Make a section in the document with the custom problem count
\enterProblemHeader{\homeworkProblemName} % Header and footer within the environment
}{
\exitProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

\newcommand{\problemAnswer}[1]{ % Defines the problem answer command with the content as the only argument
\noindent\framebox[\columnwidth][c]{\begin{minipage}{0.98\columnwidth}#1\end{minipage}} % Makes the box around the problem answer and puts the content inside
}

\newcommand{\homeworkSectionName}{}
\newenvironment{homeworkSection}[1]{ % New environment for sections within homework problems, takes 1 argument - the name of the section
\renewcommand{\homeworkSectionName}{#1} % Assign \homeworkSectionName to the name of the section from the environment argument
\subsection{\homeworkSectionName} % Make a subsection with the custom name of the subsection
\enterProblemHeader{\homeworkProblemName\ [\homeworkSectionName]} % Header and footer within the environment
}{
\enterProblemHeader{\homeworkProblemName} % Header and footer after the environment
}

%----------------------------------------------------------------------------------------
%	NAME AND CLASS SECTION
%----------------------------------------------------------------------------------------

\newcommand{\hmwkTitle}{Java/C++/Python Exercises} % Assignment title
\newcommand{\hmwkDueDate}{Tuesday,\ November\ 17,\ 2015} % Due date
\newcommand{\hmwkClass}{Continuous Integration Seminar} % Course/class
\newcommand{\hmwkClassTime}{13h30} % Class/lecture time
\newcommand{\hmwkClassInstructor}{\url{sed.inrialpes.fr}} % Teacher/lecturer
\newcommand{\hmwkAuthorName}{Maurice Br\'{e}mond, Ga\"{e}tan Harter, David Parsons -- SED INRIA Rh\^{o}ne-Alpes} % Your name


%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
%\vspace{2in}
\textsc{\hmwkClass}\\
\textbf{\hmwkTitle}\\
%\normalsize\vspace{0.1in}\small{\hmwkDueDate}\\
\vspace{0.1in}\large{\textit{\hmwkClassInstructor}}%\ \hmwkClassTime}}
%\vspace{3in}
}

\author{\textsf{\hmwkAuthorName}}
\date{\textit{\hmwkDueDate}} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

%\newpage
\tableofcontents
%\newpage
\clearpage

%----------------------------------------------------------------------------------------
%	JAVA
%----------------------------------------------------------------------------------------

% To have just one problem per page, simply put a \clearpage after each problem
\begin{homeworkProblem}[Java Exercise]

\section{Preamble}

To go through this exercise, you will need to install~:
\begin{itemize}
\item \texttt{Git} (apt-get install git | yum install git)
\item A JDK (apt-get install openjdk-7-jdk | yum install java-1.7.0-openjdk)
\item \texttt{Maven} (apt-get install maven | yum install apache-maven)
\end{itemize}

You also need an account on both \url{gforge.inria.fr} and \url{ci.inria.fr} and to be a member of the \texttt{tpcisedra} project on both platforms.

\section{Setup}

\subsection{Create a personal copy of the git repository from INRIA forge and clone it}
First, you will create your personal \texttt{git} repository on the INRIA forge as a branch of the main repository for the \texttt{tpcisedra} project~:
\begin{itemize}
\item Go to \url{https://gforge.inria.fr/projects/tpcisedra/}
\item Click on the \textbf{\texttt{CODE SOURCE}} or \textbf{\texttt{SCM}} tab
\item Click on \textbf{\texttt{Create a personal repository}}
\item Back to the \textbf{\texttt{SCM}} tab, look for the command to access your personal repository.
\end{itemize}

\textbf{WARNING~: do not use the anonymous access (containing \texttt{anonscm}) }


Then on a terminal, clone the content of your personal \texttt{git} repository. The correct command should look like this~:
\begin{lstlisting}
$ git clone git+ssh://<yourlogin>@scm.gforge.inria.fr/gitroot/tpcisedra/
    users/<yourlogin>.git
$ cd <yourlogin>/java
\end{lstlisting}

\
You should retrieve the following file tree~:\\
{\centering\small
            \begin{minipage}[t]{0.3\linewidth}
\dirtree{%
.1 tpcisedra/java.
.2 pom.xml.
.2 src.
.3 main.
.4 java.
.5 fr.
.6 inria.
.7 sed.
.8 Sphere.java.
.3 tst.
.4 java.
.5 fr.
.6 inria.
.7 sed.
.8 SphereTest.java.
}
\end{minipage}
}


The project is made up of~:
\begin{itemize}
\item A Maven \textbf{\texttt{Project Object Model}} file named \texttt{pom.xml}
\item A file \texttt{Sphere.java} implementing the class \texttt{Sphere}
\item A file \texttt{SphereTest.java} implementing its test class \texttt{SphereTest}.
\end{itemize}

\subsection{Check that you can build the project}
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn package
\end{lstlisting}

You should see these lines (among others)~:
\begin{lstlisting}
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
\end{lstlisting}



%--------------------------------------
\section{Testing your code locally}

\subsection{Run the (single) test}
\begin{lstlisting}
$ mvn test
\end{lstlisting}

You should see something like
\begin{lstlisting}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running fr.inria.sed.SphereTest
Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.069 sec

Results :

Tests run: 1, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
\end{lstlisting}



%--------------------------------------
\section{Testing your code remotely on ci.inria.fr}

\subsection{Log into the project's Jenkins instance}
\begin{itemize}
\item Connect to the INRIA Continuous Integration \texttt{Web} portal~: \url{https://ci.inria.fr/}
\item Log in and click \textbf{\texttt{Dashboard}} in the top menu
\item As you should have been added as member of the project \textbf{\texttt{TPCISedRa}}, click on the \textbf{\texttt{Jenkins}} button.
You may be prompted to log into \texttt{Jenkins}, use the same login/passwd as for the \texttt{ci.inria.fr} portal.
\end{itemize}

\subsection{Create a new Jenkins item}
From our \texttt{Jenkins} dashboard page (\url{https://ci.inria.fr/tpcisedra/})~:
\begin{itemize}
\item Click \textbf{\texttt{New Item}} in the menu on the left
\item Provide a name for this new item (avoid spaces since it is likely to lead to errors)
\item Select \textbf{\texttt{Maven project}}.
\end{itemize}

\subsection{Git configuration}
In the \textbf{\texttt{Configuration}} page (which you will be redirected to after clicking \textbf{\texttt{OK}} on the \textbf{\texttt{New Item}} page)~:
\begin{itemize}
\item Choose \texttt{git} as your \textbf{\texttt{Source Code Manager}}
\item Copy the \emph{anonymous} url to your personal repository into the appropriate field~:
\begin{lstlisting}
https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<yourlogin>.git
\end{lstlisting}
\end{itemize}
\end{homeworkProblem}

\subsection{Build configuration}
In the \textbf{\texttt{Build}} section~:
\begin{itemize}
\item Change the root \texttt{POM} path to \texttt{java/pom.xml}
\item Type \texttt{test} in \textbf{\texttt{Goals and options}} section.
\end{itemize}

\subsection{Save and run}
\begin{itemize}
\item Click \textbf{\texttt{Save}} at the bottom of the page
\item Click \textbf{\texttt{Build Now}} in the menu on the left.
\end{itemize}

\subsection{Check the output}
In the \textbf{\texttt{Build History}} on the left~:
\begin{itemize}
\item Click on the last build (hopefully $\#1$)
\item Select \textbf{\texttt{Console Output}}
\item You can also check the \textbf{\texttt{Test Result}}.
\end{itemize}


%--------------------------------------
\section{Exercise 1}

Have a look at the code of the method \texttt{Sphere::computeVolume()}.\\
To do so, edit \texttt{tpcisedra/java/src/main/java/fr/inria/sed/Sphere.java}.

The code should be like that~:
\begin{lstlisting}
public double computeVolume1() {
  return 4 * Math.PI * Math.pow(radius_, 3) / 3;
}
\end{lstlisting}


We might want the value~: \verb?4 * Math.PI / 3? to be computed once and for all.

\subsubsection{TODO~:}
\begin{itemize}
\item Extract this value into a class data member
\item Run the test again. It should fail.
\end{itemize}

Here is the output you should get~:
\begin{lstlisting}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running fr.inria.sed.SphereTest
Tests run: 1, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.076 sec <<< FAILURE!

Results :

Failed tests:   testComputeVolume(fr.inria.sed.SphereTest):
    expected:<14.137166941154069> but was:<14.137166941154067>

Tests run: 1, Failures: 1, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
\end{lstlisting}

\subsubsection{TODO~:}
\begin{itemize}
\item Check that tests fail on \texttt{Jenkins} instance.\\
Hint~: Have you commited and pushed your changes ?
\end{itemize}

\section{Exercise 2}

Why does the test in \texttt{SphereTest.java} fail ?

This is because of floating point arithmetics \emph{rounding errors}.

Our response to this issue strongly depends on what kind of application we are working on~:
\begin{itemize}
\item In some cases, we want to be aware that something has changed, even when the change is the tiniest. In that case, the test we already have is just what we want.
\item In other cases, we need not worry about such a small difference and hence do not want to be bothered by tests complaining.
\end{itemize}

\subsubsection{TODO~:}
\begin{itemize}
\item Find a way to modify the appropriate test in \texttt{SphereTest.java}
so small rounding differences do not cause errors.
\item Check that tests pass on CI.
\end{itemize}


%--------------------------------------
\section{Test Coverage}

At this stage, all our tests pass. But what does that mean regarding our application ?

Not much you may say, but can you quantify it and will you be able to tell on a real project ?

This is when \textbf{test coverage} becomes handy.

\subsection{Run test coverage}

Run the following \texttt{maven} command~:
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn cobertura:cobertura
\end{lstlisting}

\texttt{Cobertura} should have produced test coverage results in the following directory~:\\
\texttt{yourpath/tpcisedra/java/target/site/cobertura}


Use your favorite \texttt{Web} browser (\texttt{firefox}, \texttt{chrome}, \texttt{iceweasel}, ...) to visualize the generated results of the test coverage~:
\begin{lstlisting}
$ firefox target/site/cobertura/index.html &
\end{lstlisting}

\section{Exercise 3}

\subsubsection{TODO~:}

\begin{itemize}
\item Populate your tests to achieve 100\% test coverage.\\
Hint~: you may not need any additional tests ;)
\end{itemize}


\subsection{Integrate cobertura to your reporting local Website}

Add the following to the file  \texttt{pom.xml}
\begin{lstlisting}
  <reporting>
    <plugins>
      <plugin>
        <groupId>org.codehaus.mojo</groupId>
        <artifactId>cobertura-maven-plugin</artifactId>
        <version>2.7</version>
      </plugin>
    </plugins>
  </reporting>
\end{lstlisting}

The report generation is now included in the build life cycle (\textbf{\texttt{site}} phase).

\subsubsection{TODO~:}

\begin{itemize}
\item Generate the report~:
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn site
\end{lstlisting}

\item Use your favorite \texttt{Web} browser (\texttt{firefox}, \texttt{chrome}, \texttt{iceweasel}, ...) to visualize the generated report~:
\begin{lstlisting}
iceweasel target/site/project-reports.html &
\end{lstlisting}
\end{itemize}

\section{Exercise 3bis - Coverage Report on Jenkins}

\subsection{Adding build feedback}
One of the good things with \texttt{Jenkins} is its ability to nicely present your test results. \\
The tools we used to run tests and code quality checks have been selected based on the availability of the corresponding \texttt{Jenkins} plugins.

\subsection{Add coverage report}
\begin{itemize}
\item Go back to your item's configuration page (use the menu on the left)
\item Replace your build's \textbf{\texttt{Goals and options}} with~: \\
\texttt{cobertura:cobertura -Dcobertura.report.format=xml}
\item Click on \textbf{\texttt{Add post-build action}} and select \textbf{\texttt{Publish Cobertura Coverage Report}} from the drop-down menu
\item The \textbf{\texttt{Cobertura xml report pattern}} is~:\\
\texttt{**/target/site/cobertura/coverage.xml} (it is the example provided below the field)
\item Save and Run the test
\item Check the output~: in the \texttt{Build History} on the left, click on the last build, you should have a new entry named \textbf{\texttt{Coverage Report}}, have a look at it
\end{itemize}



\section{Add a new class to our project}

Let's add a new class \texttt{Alphabet} and its test class \texttt{AlphabetTest} to our project~:
\begin{lstlisting}
$ git merge alpha
\end{lstlisting}


\section{Exercise 4}
\begin{itemize}
\item Generate and visualize the corresponding coverage report
\item Make what changes are necessary to achieve 100\% test coverage
\item Check that you get the same results on \texttt{Jenkins}.
\end{itemize}

%--------------------------------------
\section{Stylecheck}

\subsection{Run a style checker}

Let's try and run a style checker~:
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn checkstyle:checkstyle
\end{lstlisting}
We get plenty of errors with the default style \verb?sun_checks.xml?.

Our coding style is closer to \texttt{Google} style than it is to \texttt{Sun} style.

\subsection{Run Google style checker}

Try running with \texttt{Google} checks (provided by the plugin)
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn checkstyle:checkstyle -Dcheckstyle.config.location=google_checks.xml
\end{lstlisting}
NOTE~: this can also be achieved by adding the following lines to your \texttt{pom.xml}~:
\begin{lstlisting}
  <properties>
    <checkstyle.config.location>checkstyle-test.xml</checkstyle.config.location>
  </properties>
\end{lstlisting}

It is getting better but we might want to make a few changes to this default behaviour.

\section{Exercise 5}

\subsubsection{TODO~:}

\begin{itemize}
\item Retrieve a local copy of \texttt{Google} checks
\begin{lstlisting}[breaklines=true]
$ wget https://raw.githubusercontent.com/checkstyle/checkstyle/18f6ebbcad23e88e3ae30fc79be464b8b7772a0d/google_checks.xml
\end{lstlisting}
\item  Modify the file \texttt{google\_checks.xml} so that it accepts single character parameter names.
\item You may also consider removing trailing underscores from data members or amending \texttt{checkstyle.xml}
\end{itemize}

\section{Integrate checkstyle to your reporting local Website}

Add the following to the file \texttt{pom.xml}
\begin{lstlisting}
  <reporting>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-checkstyle-plugin</artifactId>
        <version>2.16</version>
      </plugin>
    </plugins>
  </reporting>
\end{lstlisting}

The check style report is now included in the build life cycle (\textbf{\texttt{site}} phase).

\subsubsection{TODO~:}

\begin {itemize}
\item Generate the report~:
\begin{lstlisting}
$ pwd
yourpath/tpcisedra/java
$ mvn site
\end{lstlisting}
\item Use your favorite \texttt{Web} browser (\texttt{firefox}, \texttt{chrome}, \texttt{iceweasel}, ...) to visualize the generated report~:
\begin{lstlisting}
$ firefox target/site/project-reports.html &
\end{lstlisting}
\end{itemize}

\section{Exercise 5bis - Checkstyle Report on Jenkins}

\subsubsection{TODO~:}
\begin{itemize}
\item Go back to your item's \textbf{\texttt{configuration}} page.
\item In the \textbf{\texttt{Build}} section, set the \texttt{Goals and options} field to~:\\
\texttt{checkstyle:checkstyle -Dcheckstyle.config.location=google\_checks.xml}
\item In the \textbf{\texttt{Build Settings}} section, check the \textbf{\texttt{Publish Checkstyle analysis results}} box.
\item Save and run the test.
\item Check the output~: in the \textbf{\texttt{Build History}} on the left, click on the last build, you should have a new entry named \textbf{\texttt{Checkstyle Warnings}}. Have a look at it.
\end{itemize}

\clearpage



%----------------------------------------------------------------------------------------
%   PYTHON
%----------------------------------------------------------------------------------------
\begin{homeworkProblem}[Python Exercise]

\subsection{Preamble}

In this exercice, you will learn how to install your \texttt{Python} program with
packaging tools, test it, measure the tests code coverage, and perform some
static code analysis. And finally do this in a single command for multiple
\texttt{Python} versions and environments.

In the same time, you will use all these tools on \texttt{Jenkins} and use visualization
plugins for their output on it.

\subsubsection{Tools presentation}

For this you will use the following tools~:

\texttt{setuptools} packages your project,
\texttt{unittest} to write tests (standard library),
\texttt{nose} tools run tests and format the results,
\texttt{mock} allow replacing function or objects during tests,
\texttt{pylint} provide static code analysis and style checking,
\texttt{pep8} verifies code compliancy to \texttt{Python} PEP8 style convention
and \texttt{tox} is a virtual environment based test automation tool.


\subsection{Setup}

\subsubsection{Create and clone your personal copy of the repository}
First, you will create your personal \texttt{git} repository on the INRIA forge as a branch of the main repository for the \texttt{tpcisedra} project~:
\begin{itemize}
\item Go to \url{https://gforge.inria.fr/projects/tpcisedra/}
\item Click on the \textbf{\texttt{CODE SOURCE}} or \textbf{\texttt{SCM}} tab
\item Click on \textbf{\texttt{Create a personal repository}}
\item Back to the \textbf{\texttt{SCM}} tab, look for the command to access your personal repository.
\end{itemize}

\textbf{WARNING~: do not use the anonymous access (containing \texttt{anonscm}) }


Then on a terminal, clone the content of your personnal \texttt{git} repository. The correct command should look like this~:
\begin{lstlisting}
$ git clone git+ssh://<yourlogin>@scm.gforge.inria.fr/gitroot/tpcisedra/
    users/<yourlogin>.git
$ cd <yourlogin>/python
\end{lstlisting}

You should have retrieved the following file tree~:\\
{\centering\small
  \begin{minipage}[t]{0.3\linewidth}
    \dirtree{%
      .1 tpcisedra/python.
      .2 sphere.
      .2 tp\_ci\_sed.
      .3 \_\_init\_\_.py.
      .3 sphere.py.
      .3 test.
      .4 \_\_init\_\_.py.
      .4 sphere\_test.py.
      .2 raw.
      .3 \#file used later.
    }
  \end{minipage}
}


\subsection{Project presentation}

This project aims to compute a sphere volume.
As simple as it can be, we want it packaged, tested, and we want to have this
nice \verb=build|passing= icon on \texttt{github}~: \includegraphics[height=10pt]{build_passing}.

Your goal is to create a package, named \texttt{tp\_ci\_sed}, with a \texttt{sphere} submodule
and a command line interface (or \texttt{cli}) script to run it.

\subsubsection{Exercise 1}

\begin{itemize}
\item Try the \texttt{sphere} script.
\end{itemize}

\subsubsection{Exercise 2}

\begin{itemize}
\item Write the \texttt{Sphere.volume} method.\\
For that, use \texttt{math} module and remember volume formula you learned in school~:\\
$ 4 * \Pi * R^3 / 3 $ 
\footnote{Volume of a $1.5$ radius sphere is around $14.137$}.
\item  Commit your code with a meaningfull message and push.
\end{itemize}

\subsubsection{Releasing your code}

Now, is your package ready to use by everyone ? Can it be installed by users ?


\subsection{Packaging your code}

The first step of an integration process is being able to install the project with its dependencies.

In \texttt{Python} it is done using a \texttt{setup.py} script
written with \texttt{setuptools}
\footnote{Default \texttt{setup.py} package is \texttt{distutils} but it
does not manage automatic dependency installation}.

The script simply calls \texttt{setuptools.setup} function with the package
description~: package diretory, name, description, author, license, version,
dependencies, supported \texttt{Python} versions, \dots


\subsubsection{Usage}

This \texttt{setup.py} script is the entry point for installing and releasing
your code. It will also be used later as an entry point for tests scripts.

\begin{lstlisting}
$ python setup.py <command> [opts]

# Install the package
$ python setup.py install

# Install the package in a way that lets you edit the sources
$ python setup.py develop

# Upload your last revision to \texttt{PyPi} repository
$ python setup.py upload
\end{lstlisting}

\paragraph{Setuptools Documentation}
\url{https://pythonhosted.org/setuptools/setuptools.html}

\subsubsection{Writing the \texttt{setup.py} script}

Writing the script is basically just giving the right information in the right
format. Usually adapting an existing one is simple enough so it is provided in
this exercise.

Copy the \texttt{first} script from the \texttt{raw} folder as \texttt{setup.py}.
\begin{lstlisting}
$  cp raw/first setup.py
$  cat setup.py
#! /usr/bin/env python
# -*- coding:utf-8 -*-

import os
from setuptools import setup, find_packages
...
\end{lstlisting}

\subsubsection{Exercise 3}
\begin{itemize}
\item Open the \texttt{setup.py} script and look at the \texttt{setup} function
arguments.
\end{itemize}

\paragraph{Package dependency}
Instead of writing in a \texttt{README} file explaining which packages are required by your project,
those packages can be automatically installed with \texttt{setuptools}.
Dependencies should be listed using \texttt{install\_requires} parameter. In the example below, \texttt{argparse} dependency  will be installed with the package.

\begin{lstlisting}
setup(
    ...,
    install_requires=['argparse'],
)
\end{lstlisting}

Depending on your needs, you can specify the version with \texttt{==, <, !=} operators.

\begin{description}
\item[Note]
By default \texttt{setuptools} uses \texttt{PyPi} to find packages but can be configured
to install from many places, like an existing \texttt{git} repository or an \texttt{http} url
\footnote{\url{https://pythonhosted.org/setuptools/setuptools.html\#dependencies-that-aren-t-in-pypi}}.
\end{description}


\paragraph{Package version} \texttt{Python} package version is usually accessible
at \texttt{package\_name.\_\_version\_\_} and should be consistent with the
version in \texttt{setup.py} .

Importing the package in \texttt{setup.py} script is a source of import
and code coverage errors
\footnote{Don't import your package in \texttt{setup.py}
\url{https://stackoverflow.com/q/11279096/395687}}.

To prevent that, package \texttt{\_\_init\_\_.py} file can be read and parsed
manually to find the version.

\paragraph{}
Package version can be obtained using~:
\begin{lstlisting}
$ python setup.py --version
\end{lstlisting}


\subsubsection{Exercise 4}

\begin{itemize}
\item Find where the version is stored and how it is retrieved in the
\texttt{setup.py} script.
\end{itemize}

\subsection{Semantic versioning}

Versioning should help users follow features addition and know when incompatible
changes have been introduced.
Semantic Versioning gives you simple rules for changing your version numbers.

From  \url{http://semver.org/} summary~:
\begin{quote}
Given a version number MAJOR.MINOR.PATCH, increment the~:

\begin{itemize}
	\item MAJOR version when you make incompatible API changes,
	\item MINOR version when you add functionality in a backwards-compatible manner, and
	\item PATCH version when you make backwards-compatible bug fixes.
\end{itemize}
Additional labels for pre-release and build meta-data are available as extensions to the MAJOR.MINOR.PATCH format.
\end{quote}

Later on, remember to increment the version when you change the
API. However, as the code is still in \texttt{alpha} so you should increment
\texttt{MINOR} instead of \texttt{MAJOR}.


\subsection{Tests}

Executing your code in command line and visually verifying the result consists in testing.
However some parts of the code may be hard to reach from the \texttt{cli}, and are hard to
test this way. Also, we want to automate this step and make it repeatable.

So basically, we need to write code to execute our code and verify the output.
And to simplify the organization we will use existing tools to write them.

\paragraph{}In this section you will write tests using \texttt{unittest} and
execute them with \texttt{nosetests} tool.

Install the \texttt{nose} tools dependencies~:
\begin{lstlisting}
$ sudo -H pip install --upgrade  nosetests nose-xcover
\end{lstlisting}

The test \texttt{test\_volume\_0} has already been written as an example. Run it with \texttt{nosetests}
\begin{lstlisting}
$ nosetests -v
test_volume_0 (tp_ci_sed.test.sphere_test.TestSphere) ... ok

----------------------------------------------------------------------
Ran 1 test in 0.006s

OK
\end{lstlisting}

Now go in \texttt{tp\_ci\_sed/test/sphere\_test.py} to see the implementation.

\paragraph{unittest}
framework\footnote{\url{https://docs.python.org/2/library/unittest.html}}
is the \texttt{Python} implementation of \texttt{JUnit}.

It provides a \texttt{TestCase} base class to help writing tests.
This class implements several assert functions and also runs \texttt{setUp} and
\texttt{tearDown} methods before and after each test if implemented.
This helps configuring a test environment.


\subsubsection{Exercise 5}

\texttt{test\_volume\_0} is not enough to validate your code.
\begin{itemize}
\item Add another test to validate the volume computation with~:\\
$radius=1.5$ where $volume=14.137166941154069$
\item Commit your code with the new test.
\end{itemize}


\subsection{Jenkins setup}

Log into the project's \texttt{Jenkins} instance~:

\begin{enumerate}
\item Connect to the INRIA Continuous Integration \texttt{Web} portal~: \url{https://ci.inria.fr/}.

\item Log in and click \textbf{\texttt{Dashboard}} in the top menu
\item You should have been added to project \textbf{\texttt{TPCISedRa}}, click on the \textbf{\texttt{Jenkins}} button.
You may be prompted to log into \texttt{Jenkins}, use the same login/passwd as for the \texttt{ci.inria.fr} portal.
\end{enumerate}

Running your first test on CI~:
\begin{itemize}
\item From our \texttt{Jenkins} dashboard page (\url{https://ci.inria.fr/tpcisedra/}), click \textbf{\texttt{New Item}} in the menu on the left
\item Provide a name for this new item (avoid spaces since it is likely to lead to errors) and select \textbf{\texttt{Freestyle project}}
\end{itemize}


\texttt{Git} configuration~:
\begin{itemize}
\item In the new item's configuration page (which you will be redirected to after clicking \textbf{\texttt{OK}}), choose \texttt{Git} as your \textbf{\texttt{Source Code Manager}}
\item Copy the \emph{anonymous} URL to your personal repository into the appropriate field~:

\begin{lstlisting}
https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<yourlogin>.git
\end{lstlisting}
\end{itemize}

An important step for the continuous integration step is the build trigger.

A simple possibility is to choose to build periodically, this is
suitable for some nightly or weekly tests that may be time consuming
and are not meant to be launched after each commit, but this should be
avoided for short periods.  In our case, we want the results to be
displayed as soon as possible so we choose to launch the build after a
post-commit hook~: \footnote{It is explained in \url{ci.inria.fr} documentation in the FAQ}

\begin{itemize}
\item Click on \textbf{\texttt{Poll SCM}}
\item In the \textbf{\texttt{Schedule}} field, cut and paste~:\\
\texttt{\# Leave empty. We don't poll periodically, but need polling enabled to let HTTP trigger work}
\end{itemize}

Then on the INRIA gforge server, create the post-commit hook \texttt{post-receive}~:

\begin{lstlisting}
$ ssh <your gforge login>@scm.gforge.inria.fr
$ cd /gitroot/tpcisedra/users/<your gforge login>.git/hooks
$ touch post-receive
$ chmod +x post-receive
\end{lstlisting}

And then create the executable file \texttt{post-receive}~:
\begin{lstlisting}[breaklines=true]
#!/bin/sh
wget --auth-no-challenge --no-check-certificate -q -O -
http://ci.inria.fr/tpcisedra/git/notifyCommit?url=https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<your gforge login>.git
\end{lstlisting}

%%
For this, you can copy the following file, and simply modify the login in the script:
\begin{lstlisting}[breaklines=true]
$ cp /gitroot/tpcisedra/users/bremond.git/hooks/post-receive /gitroot/tpcisedra/users/<your gforge login>.git/hooks
\end{lstlisting}


\subsubsection{Exercise 6}

Add a new build step using \textbf{\texttt{Virtualenv Builder}}.

Using a \texttt{virtualenv} puts the code execution in a separated \texttt{Python}
environment. This will allow installing packages for this build.

Now in this field, you inform \texttt{Jenkins} how to build and test the project.
\begin{lstlisting}
# Install dependencies
sudo -H pip install --upgrade  nosetests nose-xcover

# Go in source directory
cd python

# Run tests and generate XML test results
nosetests -v --with-xunit
\end{lstlisting}

Then add \texttt{Jenkins} test result report and build:
\begin{itemize}
    \item Click on \textbf{\texttt{Post build Actions}} and
        select \texttt{Publish JUnit test result report}]
    \item For \texttt{Test report XMLs} put \texttt{**/*tests.xml}
        to scan for all files ending  with 'tests.xml'.
    \item Then save the project and verify the configuration with a click on
        \textbf{\texttt{Build Now}} in the menu on the left.
    \item In the \texttt{Build History} on the left, click on the last build
        (hopefully \#1), then select \texttt{Console Output}.
        You can also check the \texttt{Test Result}.
\end{itemize}


\subsection{Refactoring}

Now that your code is tested, you can safely start refactoring it.
In our formula, the $ 4 * \Pi / 3 $ part can be computed only once instead of
at each \texttt{volume} call.

\subsubsection{Exercise 7}

\begin{itemize}
\item Move it in a class variable and use it in the \texttt{volume} method.
\item Run the tests again. It should fail~:

\begin{lstlisting}
$ nosetests -v
test_volume_0 (tp_ci_sed.test.sphere_test.TestSphere) ... ok
test_volume_1_5 (tp_ci_sed.test.sphere_test.TestSphere) ... FAIL

======================================================================
FAIL: test_volume_1_5 (tp_ci_sed.test.sphere_test.TestSphere)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ".../tp_ci_sed/test/sphere_test.py", line 19, in test_volume_1_5
    self.assertEqual(14.137166941154069, vol)
AssertionError: 14.137166941154069 != 14.137166941154067

----------------------------------------------------------------------
Ran 2 tests in 0.007s

FAILED (failures=1)
\end{lstlisting}

\begin{description}
\item[Note] If it does not fail, ask for help, magic numbers technique failed.
\end{description}

However, let's assume it is successfull and commit your modifications.
\begin{lstlisting}
$ git commit -m "Precompute 4pi/3"
$ git push
\end{lstlisting}
\item The test should now fail on \texttt{Jenkins}. See the Console output.
\end{itemize}

Even if you didn't test it on your computer before committing, at least it is
tested somewhere and the error can be detected.

\paragraph{Version} Did you remember to increase the package version?


\subsubsection{Refactoring error}
Why does the test fail?

Because of floating point arithmetics \emph{rounding errors}.

Our response to this issue strongly depends on what kind of application we are
working on~:
\begin{itemize}
\item In some cases, we want to be aware that something has changed, even when
    the change is the tiniest. In that case, the test we already have is just what we want.
\item In other cases, we need not worry about such a small difference and hence
    do not want to be bothered by tests complaining.
\end{itemize}

Here, the code result is correct, so it should pass.

\subsubsection{Exercise 8}

\begin{itemize}
\item Find a way to modify the test so small rounding differences do not cause errors
\item Commit, push and verify \texttt{Jenkins} result
\end{itemize}
\paragraph{Hint~: } See the list of \texttt{unittest} assert functions~:

\url{https://docs.python.org/2/library/unittest.html\#unittest.FunctionTestCase}


\subsection{Code coverage}

When running tests, the information of what part of the code has been tested is
also meaningful. It is often refered as "code coverage".

With \texttt{Python} it can be generated with the \texttt{coverage} package, but also
directly with \texttt{nosetests} and \texttt{nose-xcover}.

To get the coverage output, run~:
\begin{lstlisting}
$ nosetests -v --with-xcoverage --cover-erase  --cover-inclusive \
    --cover-branches --cover-html --cover-package  tp_ci_sed

test_volume_0 (tp_ci_sed.test.sphere_test.TestSphere) ... ok
test_volume_1_5 (tp_ci_sed.test.sphere_test.TestSphere) ... ok

Name                  Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------
tp_ci_sed.py              1      0      0      0   100%
tp_ci_sed/sphere.py      19      6      2      1    67%   19, 28-32, 36, 35->36
-----------------------------------------------------------------
TOTAL                    20      6      2      1    68%
----------------------------------------------------------------------
Ran 2 tests in 0.012s

OK
\end{lstlisting}

You can read the coverage output directly in the \texttt{nosetests} output.
But a human readable \texttt{html} report and an \texttt{xml} report for \texttt{Jenkins} are also generated.


\begin{lstlisting}
$ ls
cover coverage.xml  raw  sphere  tp_ci_sed
 file coverage.xml
coverage.xml: XML document text
\end{lstlisting}

Look at the \texttt{html} report using a \texttt{Web} browser~:

\begin{lstlisting}
$ firefox cover/index.html &
\end{lstlisting}


\subsection{\texttt{setup.py} sub-commands}

As running \texttt{nosetests} with all the options is quite a pain, you will use
\texttt{setuptools} to configure the \texttt{nosetests} command.

Calling \texttt{nosetests} can be done using~:
\begin{lstlisting}
$ python setup.py nosetests

...

reading manifest file 'tp_ci_sed.egg-info/SOURCES.txt'
writing manifest file 'tp_ci_sed.egg-info/SOURCES.txt'
..
----------------------------------------------------------------------
Ran 2 tests in 0.006s

OK
\end{lstlisting}

Configuring \texttt{setup.py} commands requires adding options in a
\texttt{setup.cfg} file.

Copy the \texttt{second} script from the \texttt{raw} folder as \texttt{setup.cfg}.
\begin{lstlisting}
$ cp raw/second setup.cfg
$ cat setup.cfg
\end{lstlisting}

The first part is \texttt{nosetests} configuration.
It allows coverage and test \texttt{XML} results
and also searching for all type of tests (unittest, doctest).

Re-run the command~:
\begin{lstlisting}
$ python setup.py nosetests

...

----------------------------------------------------------------------
XML: /home/harter/work/tpcisedra/python/nosetests.xml
Name                  Stmts   Miss Branch BrPart  Cover   Missing
-----------------------------------------------------------------
tp_ci_sed.py              1      0      0      0   100%
tp_ci_sed/sphere.py      19      6      2      1    67%   19, 28-32, 36, 35->36
-----------------------------------------------------------------
TOTAL                    20      6      2      1    68%
----------------------------------------------------------------------
Ran 2 tests in 0.012s

OK
\end{lstlisting}


Now running the tests with \texttt{python setup.py nosetests} also generates the
coverage report.


\subsubsection{Coverage on Jenkins}

\begin{itemize}
    \item First change the \verb=nosetests -v --with-xunit= build action with
        \verb=python setup.py notestests=.
    \item Add \textbf{\texttt{Post build Actions}} \texttt{Publish Cobertura Coverage Report}.
    \item Configure \texttt{Cobertura xml report pattern} with: \texttt{**/coverage.xml}
\end{itemize}


\paragraph{Workaround}

As source files are not located at root directory, \texttt{Cobertura} plugin fails to find them correctly.
A solution is to create a symbolic link to the source directory.
\begin{itemize}
  \item Add a build step \texttt{Execute shell} with~:
\begin{lstlisting}
# Hack to help cobertura find source files
$ ln  -nfs python/tp_ci_sed  tp_ci_sed
\end{lstlisting}
\item Commit your code and push
\item Manually re-run a build to get \texttt{Cobertura} plugin graph (it needs more than one build)
\item You can click on the report to see per-file coverage infos.
\end{itemize}


\subsection{Code static analysis and style}

\texttt{Python} is a dynamic language where many things are evaluated at run-time.
So it is different from compiled languages. It means that if you do typos,
errors may only occur when running the program.
Using a static analysis program can detect errors without executing your program.

Another way to avoid typos and increase readability, is using coding standards
for formatting your code. It make all your code look the same and it eases comprehension.

For \texttt{Python} there is even an official coding style guide defined in the
\texttt{Python} Enhancement Proposal 8 (PEP8\footnote{\url{https://www.python.org/dev/peps/pep-0008/}}).


\paragraph{}In this section you will use two tools  to perform static analysis and code style checking~: \texttt{Pylint} and \texttt{PEP8}.

They will be run using the \texttt{setup.py} script and so their
configuration is set in \texttt{setup.cfg}.

\begin{itemize}
\item Install dependencies. Note the \texttt{setuptools-XXXX} which provides
\texttt{setup.py} wrapper.
\begin{lstlisting}
$ sudo -H pip install --upgrade  pylint pep8 setuptools-lint setuptools-pep8
\end{lstlisting}
\item Run the two commands~:
\begin{lstlisting}
$ python setup.py lint
$ python setup.py pep8
\end{lstlisting}
\end{itemize}

You should get a lot of errors and warnings.

\subsubsection{Exercise 9}

\begin{itemize}
\item Add \texttt{lint} and \texttt{pep8} in \texttt{Jenkins} build step
\item To get the reports use \textbf{\texttt{Post build Actions}} named
\texttt{Scan for compiler warnings} and in \texttt{Scan console log} add
\texttt{Pep8} and \texttt{Pylint}
\item Re-run the build manually.
\end{itemize}

\subsubsection{Exercise 10}

\begin{itemize}
\item Fix some of the errors, but do not spend too much time.
However, putting an empty docstring to get rid of the message is evil, it is
your code documentation !
\item Commit and see the output on \texttt{Jenkins}.
\end{itemize}

\begin{description}
  \item[Note] The tools may return some false-positive.
    In this case it is possible to disable the error messages.
    Refer to the documentation when needed~:
    \url{http://docs.pylint.org/message-control}
\end{description}


\subsection{All tests in one command}

Now that we sum up what we have, testing all your application with the previous
tools is simply running the three following commands~:

\begin{lstlisting}
$ python setup.py nosetests
$ python setup.py lint
$ python setup.py pep8
\end{lstlisting}

You can write that in your documentation and let other users to do it.
Is it enough?

Do you remember to tell to install the tests dependencies?
And if you want to add another test tool? You must inform all developers to
run the new command.
And if you want to test with \texttt{Python}3 ?

Adding a \texttt{bash} script to do it would work but as we are working with \texttt{Python}, let's use the right tool.


\paragraph{tox}\footnote{\url{https://tox.readthedocs.org/en/latest/}}
Is a generic \texttt{virtualenv} based automation tool.
It lets you test that your package can be installed with different interpreters and runs
tests in each environment.

\begin{itemize}
\item Install \texttt{tox} dependency.
\begin{lstlisting}
$ sudo -H pip install --upgrade  tox
\end{lstlisting}
\item Copy the \texttt{tests\_utils} from \texttt{raw} directory~:
\begin{lstlisting}
$ cp -r raw/tests_utils .
$ ls tests_utils/
coverage-python-3.2.txt  pylint-python-2.6_3.2.txt  test-requirements.txt
\end{lstlisting}
\item Look at these files.
All tests dependencies are described in the \texttt{test-requirements.txt} file.
The two other files are specific versions for \texttt{Python} 2.6 and 3.2.
\item Copy the \texttt{tox.ini} file from \texttt{raw/third} file.
\begin{lstlisting}
$ cp -r raw/third tox.ini
\end{lstlisting}
The file content is the following~:
\lstinputlisting[caption=tox.ini,label=tox.ini]{../../Src/Python/tox.ini}
The different part of the file are~:
\begin{itemize}
\item \texttt{envlist}~: is the list of \texttt{Python} version you want to run on. Here we  only consider \texttt{Python}2.7 for the moment.
\item \texttt{deps}~: the test dependencies. With specific packages versions for \texttt{python2.6 python3.2}.
\item \texttt{commands}~: the list of test commands. The front dash \texttt{-} means "don't fail" on execution error.
\end{itemize}
From now, executing your tests simply means running \texttt{tox} and the only required dependency installed is \texttt{tox} itself.
\item Commit and push.
\end{itemize}
\
\subsubsection{Exercise 11}

\begin{itemize}
\item Update \texttt{Jenkins} main build step.
You can replace all dependencies installation with only \texttt{tox} and replace
the \texttt{setup.py} execution with \texttt{tox}.

\begin{lstlisting}
pip install --quiet --upgrade tox
cd pthon
tox
\end{lstlisting}
\item Re-run the build.
\end{itemize}

\paragraph{Other versions}
If everything succeeds, and you can test using \texttt{python3} (\texttt{Python}3 is installed in the virtual machine related to \texttt{ci.inria.fr/tpcisedra}
).
\begin{itemize}
\item Use \texttt{py32} (for \texttt{Python}3.2)
\item Re-run \texttt{tox}.
\end{itemize}
Tests should fail, at least for the \texttt{print} statement.

However, you see how easy it is to test your code on different \texttt{Python} versions.
Making a code working for \texttt{python2} and \texttt{python3} requires some time, but at least it is easy to test.


\subsection{Advanced tests writing~: mocking}


\begin{description}
    \item[mock] \url{http://www.voidspace.org.uk/python/mock/index.html}
\end{description}

When testing, it is useful to replace some part of your application to handle
a special behavior, like raising an exception, or to prevent its side effect,
like connection to an external service. It is also easier to be able to know how
an object has been used or a function been called.

In this section you will see \texttt{mock} to test the \texttt{main} function
and verify the printed output.


\begin{itemize}
\item  Install the dependency on your system. It will be installed by
\texttt{tox} in the test environment.
\begin{lstlisting}
$ sudo -H pip install --upgrade  mock
\end{lstlisting}
\end{itemize}

\texttt{mock} class provides mainly two important things~:
\begin{itemize}
    \item \texttt{Mock} class which is an object whose behaviour can be
        configured and that records all action on it.
    \item \texttt{patch} function that dynamically replaces one
        function/method/object with a \texttt{Mock} object.
\end{itemize}

\paragraph{Remark} Explaining mocks and applying is too long for this course.
So in this section you have to copy paste the code, try it and read
afterwards to understand the example. See online documentations when trying it
yourself.

\begin{itemize}
\item Copy the \texttt{fourth} file as \texttt{tp\_ci\_sed/test/sphere\_test\_main.py}
\item Re-run tests.
\begin{lstlisting}
$ cp -r raw/fourth tp_ci_sed/test/sphere_test_main.py
$ tox
\end{lstlisting}
\end{itemize}

You can see that we now have 100\% coverage.

Now open the \texttt{sphere\_test\_main.py} in a text editor and check this~:

\paragraph{Main function} In order to test the main function, the program
arguments \texttt{sys.argv} should be replaced with different values.
Here I am patching it using a \texttt{context\_manager} (\texttt{with} keyword).
It automatically applies and cleans up the patch.

\paragraph{Mocking outputs} Two methods are presented~:

The first one is mocking \texttt{sys.stdout} with a \texttt{StringIO} object and
get the written string. Here it is also done using a context manager.

Another, is mocking the file object and verify \texttt{write} call arguments.
It is presented here for \texttt{sys.stderr} by patching in \texttt{setUp} and
cleaning it with \texttt{patch.stopall()} in \texttt{tearDown}.


Both method are valid, it is just for presenting alternatives.


\paragraph{Hints~:} Some advices on patch~:

\begin{itemize}
\item When ``patching'' always verify that the mock has been called by your
 program, there are so many cases where you can just fail to patch correctly.
\item When patching a class, you should use \texttt{MockClass.return\_value} to get the instance \texttt{mock}.
\item The patching path can depend on how the module is imported, see~:
    \url{http://www.voidspace.org.uk/python/mock/patch.html#where-to-patch}.
    Read it, try it, and understand this prior testing your application.
    Basically, when patching an object imported using \texttt{import XXXX} it requires absolute patch path.
    And when an object is imported using \verb=from XXX import yyyyy=, it requires patching from the importing module.
\end{itemize}

For every other problems, look at the documentation.

\subsubsection{Code review by ChuckNorris}

\begin{itemize}
\item Add ChuckNorris post build action. It will make your code famous and better.
\end{itemize}
It displays Chuck Norris facts and a picture of Chuck adapted to your build
result (seems like the picture is not displayed but why ?)

\subsubsection{Build Passing icon}

There is a plugin for that. It is called \texttt{Embeddable Build Status},
however it requires the project to have at least ``ViewStatus'' to allow everyone
to see it. And it is not configured in this project.

But you will set it on your own \texttt{Jenkins} for your project !

Always verify on a non-authenticated browser.


\end{homeworkProblem}


\clearpage
%----------------------------------------------------------------------------------------
%   C++
%----------------------------------------------------------------------------------------
%"${)

\begin{homeworkProblem}[C++ Exercise]

\section{Preamble}

In this exercise, we will focus on the configuration of \texttt{Jenkins} for~:
\begin{enumerate}
\item A simple aspect of \texttt{C++} unit testing
\item An aspect of dynamic testing~: source coverage
\item A demonstration of static analysis with \texttt{cppcheck}.
\end{enumerate}

To perform this \texttt{C++} exercise, we rely on these development tools~:

\begin{itemize}
\item A \texttt{C++} compiler, for example \texttt{GNU C++} or \texttt{clang}.
\item A build process manager~: \texttt{CMake}
\item A testing framework~: \texttt{cppunit}
\item A static analysis tool~: \texttt{cppcheck}
\item Coverage analysis tools~: \texttt{gcov}, \texttt{lcov} \texttt{gcvor}.
\end{itemize}

On \texttt{Linux}, \texttt{BSD}, \texttt{MACOS X} systems, suitable versions may simply be installed with the package manager (\texttt{yum, apt, ...}).

For example~:
\begin{itemize}
\item On \texttt{Fedora} systems, one may use the command~:\\
\texttt{sudo yum install cmake gcc-c++ cppunit cppcheck gcov lcov}
\item On recent \texttt{Debian} or \texttt{Ubuntu} systems~:\\
\texttt{sudo apt-get install cmake gcc-c++ cppunit cppcheck gcov lcov}
\end{itemize}

For \texttt{gcovr}, use~:\\
 \texttt{sudo pip install gcovr}.

\section{Unit testing}
\subsection{Local setup}

\subsubsection{Clone the git repository from INRIA forge and create your own branch}
First, you will create your personal \texttt{git} repository on the INRIA forge as a branch of the main repository for the \texttt{tpcisedra} project~:
\begin{itemize}
\item Go to \url{https://gforge.inria.fr/projects/tpcisedra/}
\item Click on the \textbf{\texttt{CODE SOURCE}} or \textbf{\texttt{SCM}} tab
\item Click on \textbf{\texttt{Create a personal repository}}
\item Back to the \textbf{\texttt{SCM}} tab, look for the command to access your personal repository.
\end{itemize}

\textbf{WARNING~: do not use the anonymous access (containing \texttt{anonscm}) }


Then on a terminal, clone the content of your personal \texttt{git} repository. The correct command should look like this~:
\begin{lstlisting}
$ git clone \
  git+ssh://<yourlogin@scm.gforge.inria.fr/gitroot/tpcisedra/users/<yourlogin>.git
$ cd tpcisedra/cxx
\end{lstlisting}

A minimal \texttt{CMake} project is present under the file tree~:\\
{\centering\small
            \begin{minipage}[t]{0.3\linewidth}
\dirtree{%
  .1 tpcisedra/cxx.
  .2 CMakeLists.txt.
  .2 cmake.
  .3 TP.cmake.
  .2 Sphere.hpp.
  .2 Sphere.cpp.
  .2 bench.cpp.
  .2 tests.
  .3 CMakeLists.txt.
  .3 TestTP.hpp.
  .3 TestTP.cpp.
  .3 TestMain.cpp.
}
\end{minipage}
}


This \texttt{CMake} project provides the framework needed to build and test a
versionized, dynamic shared library named \textbf{\texttt{TP}} \footnote{\textbf{\texttt{TP}} for \textbf{\texttt{Travaux Pratiques}}
  in french}. The \texttt{CMake} configuration is specified in two
\texttt{CMakeLists.txt} files~:
\begin{itemize}
\item One under the main directory~: the main \texttt{CMakeLists.txt}
\item One under the \texttt{tests} directory.
\end{itemize}

The API provided by this library is at this level composed by a single \texttt{Sphere} class. The \texttt{Sphere} class offers an object constructor with the \texttt{radius} as parameter and a \texttt{volume} method.

A benchmark program named \texttt{bench.cpp} is also built and linked with the
library. Although the computation is very simple, this benchmark program may
be used to compare the influence of some compiler optimization flags.

\subsubsection{Check that you can build the project and run the test}

On a Unix system~:
\begin{itemize}
\item Create a \texttt{build} directory
\item Create the build environment with \texttt{CMake}
\item Build the project
\item Run the test.
\end{itemize}


\begin{lstlisting}
$ mkdir build
$ cd build
$ cmake ..
$ make
$ make test
\end{lstlisting}

%$

\subsubsection{Run the benchmark}

\texttt{CMake} provides pre-defined build configurations that may be chosen
with the \texttt{CMAKE\_BUILD\_TYPE} variable. Among them we are going to
consider~:
\begin{itemize}
\item \texttt{Debug} build type which sets the debug flags (\texttt{-g} with \texttt{GNU C++})
\item \texttt{Release} build type which sets some optimization flags (\texttt{-O3 -DNDEBUG} with \texttt{GNU C++})
\end{itemize}

Once a directory has been given as argument to \texttt{CMake} it remains in a
cache, the \texttt{CMakeCache.txt} file in your build directory. This cache
file is a text file and may be edited by hand.

So for next calls to \texttt{CMake}, we can use the \texttt{dot} directory as argument~:

\begin{lstlisting}
$ cmake .
\end{lstlisting}

%$

\texttt{CMake} variables may be set on the command line with \texttt{-D}
arguments~:
\begin{lstlisting}
$ cmake . -D<VARIABLE\_NAME>=<VALUE>
\end{lstlisting}

The value remains in the cache file, so when a variable has been modified once with a call to \texttt{CMake}, it is not necessary to define its value anymore on the command line.

To configure our build to produce a \texttt{Debug} type build~:
\begin{lstlisting}
$ cmake . -DCMAKE_BUILD_TYPE=Debug
$ make
$ ./bench
\end{lstlisting}

For an optimized build, we change its configuration to~:
\begin{lstlisting}
$ cmake . -DCMAKE_BUILD_TYPE=Release
$ make
$ ./bench
\end{lstlisting}

%$

Over this very simple computation, the benchmark difference between \texttt{Debug} and \texttt{Release} is not dramatic.

With \texttt{GNU C++} compiler, we can go beyond \texttt{-O3} optimization flag with the
\texttt{fast-math} option, which implies \texttt{-funsafe-math-optimizations}
and may break some of the requirements of \texttt{IEEE} and \texttt{ANSI}
standards.

To pass a specific argument to the \texttt{GNU C++} compiler, we use the variable \texttt{CMAKE\_CXX\_FLAGS}. The arguments passed on the command line to this
variable are added to the other compiler arguments. In doubt with the
generated specification, one can use the argument \texttt{VERBOSE=1} with \texttt{make} tool, in order to see all the flags passed to the compiler.

\begin{lstlisting}
$ cmake . -DCMAKE_BUILD_TYPE=Release -DCMAKE_CXX_FLAGS=-ffast-math
$ make VERBOSE=1
$ ./bench
\end{lstlisting}

%$

You should see a difference on time.

Now, let's keep this configuration in our \texttt{build} directory.

\clearpage
\subsection{Jenkins setup}

Log into the project's \texttt{Jenkins} instance~:

\begin{enumerate}
\item Connect to the INRIA Continuous Integration \texttt{Web} portal~: \url{https://ci.inria.fr/}.

\item Log in and click \textbf{\texttt{Dashboard}} in the top menu
\item As you have been added to project \textbf{\texttt{TPCISedRa}}, click on the \textbf{\texttt{Jenkins}} button.
You may be prompted to log into \texttt{Jenkins}, use the same login/passwd as for the \texttt{ci.inria.fr} portal.
\end{enumerate}

Running your first test with Jenkins~:
\begin{itemize}
\item From our \texttt{Jenkins} dashboard page (\url{https://ci.inria.fr/tpcisedra/}), click \textbf{\texttt{New Item}} in the menu on the left
\item Provide a name for this new item (avoid spaces since it is likely to lead to errors) and select \textbf{\texttt{Freestyle project}}
\end{itemize}


\texttt{Git} configuration~:
\begin{itemize}
\item In the new item's configuration page (which you will be redirected to after clicking \textbf{\texttt{OK}}), choose \texttt{Git} as your \textbf{\texttt{Source Code Manager}}
\item Copy the \emph{anonymous} URL to your personal repository into the appropriate field~:

\begin{lstlisting}
https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<yourlogin>.git
\end{lstlisting}
\end{itemize}

An important step for the continuous integration setup is the build trigger.
\\
A simple option is to choose to build periodically~: this is
suitable for some nightly or weekly tests that may be time consuming
and are not meant to be launched after each commit, but this should be
avoided for short periods.
\\
In our case, we want the results to be displayed as soon as possible, so we choose to launch the build after a \texttt{post-commit} hook~:
\footnote{It is explained in \url{ci.inria.fr} documentation in the FAQ}


\begin{itemize}
\item Click on \textbf{\texttt{Poll SCM}}
\item In the \textbf{\texttt{Schedule}} field, cut and paste~:\\
\texttt{\# Leave empty. We don't poll periodically, but need polling enabled to let HTTP trigger work}
\end{itemize}

Then on the INRIA gforge server, create the post-commit hook \texttt{post-receive}~:

\begin{lstlisting}
$ ssh <your gforge login>@scm.gforge.inria.fr
$ cd /gitroot/tpcisedra/users/<your gforge login>.git/hooks
$ touch post-receive
$ chmod +x post-receive
\end{lstlisting}

And then create the executable file \texttt{post-receive} which content is~:
\begin{lstlisting}[breaklines=true]
#!/bin/sh
wget --auth-no-challenge --no-check-certificate -q -O -
http://ci.inria.fr/tpcisedra/git/notifyCommit?url=https://scm.gforge.inria.fr/anonscm/git/tpcisedra/users/<your gforge login>.git
\end{lstlisting}

%$
For this, you can copy the following file, and simply modify the login~:
\begin{lstlisting}[breaklines=true]
$ cp /gitroot/tpcisedra/users/bremond.git/hooks/post-receive /gitroot/tpcisedra/users/<your gforge login>.git/hooks
\end{lstlisting}


\subsubsection{Exercise 1}

Add a new build step using \textbf{\texttt{Execute shell}}, where you inform \texttt{Jenkins} how to build and test the project~:

\begin{itemize}
\item You have to choose the \texttt{Debug} configuration for this build, this will be needed for coverage as we will see later.\\
In the shell working directory (the result of the command \texttt{/bin/pwd} in
this shell) \texttt{Jenkins} has cloned your source directory.
\item Then save the project and verify the configuration with a click on \textbf{\texttt{Build
Now}} in the menu on the left.
\item In the \textbf{\texttt{Build History}} on the left, click on the last build (hopefully $\#1$), then select \texttt{Console Output}.
\item You can also check the \textbf{\texttt{Test Result}}.
\end{itemize}

\subsubsection{Exercise 2}

\paragraph{First part}
Edit the implementation of the \texttt{Sphere} class~:
\texttt{tpcisedra/c++/src/Sphere.cpp} and have a look at the code of the method \texttt{Sphere::volume()}.

\begin{lstlisting}
double Sphere::volume() const
{
  return 4 * M_PI * pow (this->_radius, 3.) / 3.;
}
\end{lstlisting}

This is the method which is tested in the unique test of the library, and the test is implemented in the file~:

\texttt{tpcisedra/c++/src/tests/testTP.cpp}

Let's imagine we want to improve the efficiency of the \texttt{volume()}
method by pre-computing the value \verb?4 * Math.PI / 3?

TODO~:
\begin{itemize}
\item Extract this value into a class data member.
\item Run the benchmark. This may show only a very, very minimal improvement !
\item Run the test.
\end{itemize}

The test may still be successful~: this may depend on your hardware and compiler.

Let's assume it is successful~: do not forget to commit your modifications.

\begin{lstlisting}
$ git commit -m "precomputation of 4pi/3"
$ git push
\end{lstlisting}

The test should now fail on \texttt{Jenkins}.

Here is the output you can see on \texttt{Jenkins} console~:
\begin{lstlisting}
+ make test
Running tests...
Test project /builds/workspace/mb-cxx/build
    Start 1: TestVolume
1/1 Test #1: TestVolume .......................***Failed    0.00 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =   0.00 sec

The following tests FAILED:
	  1 - TestVolume (Failed)
\end{lstlisting}

\paragraph{Second part}

The \texttt{-funsafe-math-optimizations} implied by \texttt{-ffast-math}
allows for reordering of floating points operations and this may lead to
different results.

The direct check of equality of floating point numbers with the \texttt{==}
operator should be avoided~: so we can add a warning (only if understood by the
compiler) in order not to reproduce this kind of error.

Since version $4.6$, \texttt{GNU C++} provides this warning \texttt{-Wfloat-equal}.
With portability in mind, before adding the flag to the compiler command, we need to check that the compiler accepts it.

With \texttt{CMake}, there is no built-in function for this operation, but that
can be achieved with a simple macro~:

\begin{lstlisting}
include(TestCXXAcceptsFlag)
macro(add_cxx_compiler_flag _flag)
  string(REPLACE "-" "_" _flag_var ${_flag})
  check_cxx_accepts_flag("${_flag}" CXX_COMPILER_${_flag_var}_OK)
  if(CXX_COMPILER_${_flag_var}_OK)
    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${_flag}")
  endif()
endmacro()
\end{lstlisting}

This macro is provided in the \texttt{TP.cmake} module file under \texttt{cmake} directory.

To load this \texttt{TP} module, you need to modify the \texttt{CMakelists.txt} file~:
\begin{itemize}
\item Set the \texttt{CMake module path} to this directory~:
\begin{lstlisting}
set(CMAKE_MODULE_PATH ${CMAKE_CURRENT_SOURCE_DIR}/cmake)
\end{lstlisting}
\item Load the module \texttt{TP}. Beware~: this should be done before using the macro~:
\begin{lstlisting}
include(TP)
\end{lstlisting}
\end{itemize}

%$

On \texttt{Jenkins} side, compiler warnings can be checked in the \textbf{\texttt{Post build Actions}} step of your build project.

TODO~:
\begin{itemize}
\item In the \texttt{CMake} configuration file, \texttt{CMakeLists.txt}, include the \texttt{TP} module.
\item With the provided \texttt{CMake TP} macro, add the compiler warning to the \texttt{CMake} configuration,
\item Verify that the warning is printed during compilation.
\item Commit the code in order to check the parsing done by \texttt{Jenkins}.
\item In \texttt{Jenkins}, add the scan for compiler warnings in the \textbf{\texttt{Post build Action}} of your project.
\item Modify the appropriate test in \texttt{TestTP.cpp} so small rounding
  differences do not cause errors.\\
  \texttt{cppunit} provides a macro for this~:
  \texttt{CPPUNIT\_ASSERT\_DOUBLES\_EQUAL(expected, actual, delta)}.
\item Once it is OK and the warning has gone, commit.
\item Rebuild on \texttt{Jenkins} to check.
\end{itemize}

%$



%--------------------------------------
\section{Code coverage}

Here we get a taste of some dynamics analysis. After the tests are
executed, the code coverage tools (mainly \texttt{gcov}) show which lines of code have been involved in the execution.

\subsection{Installation}

Coverage with \texttt{gcov} needs the \texttt{GNU C++} compiler and the
\texttt{-fprofile-arcs} and \texttt{-ftest-coverage} options.

\texttt{gcov} generates raw output. We are going to use the \texttt{lcov} utility for the
post-processing and the generation of \texttt{html} pages and the \texttt{gcovr} utility in
order to present parsable results to \texttt{Jenkins}.

A \texttt{CMake} function \texttt{add\_test\_with\_coverage} is provided in the
\texttt{TP} module to simplify the whole setup.

This function, when used in place of the standard \texttt{CMake} function
\texttt{add\_test} function, provides coverage support through a new
\texttt{make coverage} target.
\\
Remark~: You can see all \texttt{make} targets usign~: \texttt{make help}.
%$

\subsubsection{Exercise 3}

TODO~:
\begin{itemize}
\item Install coverage for the test routine \texttt{TestVolume}. In the \texttt{CMake} configurations files, you need to set the coverage flags for the build of the library and the test file with the \texttt{add\_cxx\_compiler\_flag}.
\item Run a test with \texttt{make coverage}
\item Open the file \texttt{index.html} under \texttt{TestTP\_\_testVolume} directory with a \texttt{Web} browser to see the result
\item On the \texttt{Jenkins} side, modify the build process in \textbf{\texttt{Execute shell}} to add coverage target
\item And in \textbf{\texttt{Post-Build Actions}}, add \textbf{\texttt{Publish Cobertura Report}} with the \texttt{Cobertura xml} report pattern set to~:\\
\texttt{**/coverage.xml}
\item Commit.
\end{itemize}

Let's test if it works with more than one class.

Thanks to another development branch, we add a new class \texttt{Alphabet} to
our project~:
\begin{lstlisting}
$ git merge alpha-cxx
\end{lstlisting}

%$

\subsubsection{Exercise 4}
\begin{itemize}
\item Generate and visualize the corresponding coverage report
\item Improve the test coverage and commit.
\end{itemize}

%--------------------------------------
\section{Static analysis}

With our library, one can check that the following code is valid but it may not be what the programmer intended~:

\begin{lstlisting}
 Sphere s1(.1);
 Sphere s2(.2);
 std::pair<Sphere, Sphere> p(s1,2);
\end{lstlisting}

As the implicit conversion is allowed on the \texttt{Sphere} constructor, the pair of
\texttt{Sphere} objects \texttt{p} is constitued of the \texttt{Sphere} \texttt{s1} and the \texttt{Sphere} 
\texttt{Sphere(2)} which is not the same as the pair of \texttt{s1} and \texttt{s2}.
In the case of a typo in the code source, this may certainly lead to bugs.

A static code analysis may help in the discovery of those potentials bugs.

\paragraph{Use of cppcheck}

With \texttt{cppcheck} tool applied on our project, one can simply get a report using the command~:

\begin{lstlisting}
$ cppcheck <your source directory> -f -q --enable=style
\end{lstlisting}

%$

The results we obtain depends on the version of \texttt{cppcheck}!

On the virtual machine configured for \texttt{ci.inria.fr/tpcisedra}, the latest (\texttt{1.71}) \texttt{cppcheck} is installed.

\subsubsection{Exercise 5}
\begin{itemize}
\item Install this check on \texttt{Jenkins}. One have to generate an \texttt{XML} output
  (\texttt{--xml} option) and to redirect standard error to a file named
  \texttt{cppcheck-result.xml}. \texttt{Jenkins} can read this file if configured properly using the \textbf{\texttt{Post-Build}} section of your build project.
\item Fix some warnings and commit.
\end{itemize}


\end{homeworkProblem}
%----------------------------------------------------------------------------------------

\end{document}
